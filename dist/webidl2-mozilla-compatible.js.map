{"version":3,"sources":["webpack://WebIDL2/webpack/universalModuleDefinition","webpack://WebIDL2/webpack/bootstrap","webpack://WebIDL2/./lib/error.js","webpack://WebIDL2/./lib/tokeniser.js","webpack://WebIDL2/./lib/productions/base.js","webpack://WebIDL2/./lib/validators/helpers.js","webpack://WebIDL2/./lib/productions/type.js","webpack://WebIDL2/./lib/productions/default.js","webpack://WebIDL2/./lib/productions/array-base.js","webpack://WebIDL2/./lib/productions/extended-attributes.js","webpack://WebIDL2/./lib/productions/helpers.js","webpack://WebIDL2/./lib/productions/argument.js","webpack://WebIDL2/./lib/productions/token.js","webpack://WebIDL2/./lib/productions/operation.js","webpack://WebIDL2/./lib/productions/attribute.js","webpack://WebIDL2/./lib/productions/enum.js","webpack://WebIDL2/./lib/productions/includes.js","webpack://WebIDL2/./lib/productions/typedef.js","webpack://WebIDL2/./lib/productions/callback.js","webpack://WebIDL2/./lib/productions/container.js","webpack://WebIDL2/./lib/productions/constant.js","webpack://WebIDL2/./lib/productions/iterable.js","webpack://WebIDL2/./lib/productions/interface.js","webpack://WebIDL2/./lib/validators/interface.js","webpack://WebIDL2/./lib/productions/mixin.js","webpack://WebIDL2/./lib/productions/field.js","webpack://WebIDL2/./lib/productions/dictionary.js","webpack://WebIDL2/./lib/productions/namespace.js","webpack://WebIDL2/./lib/productions/callback-interface.js","webpack://WebIDL2/./lib/webidl2.js","webpack://WebIDL2/./lib/writer.js","webpack://WebIDL2/./lib/validator.js","webpack://WebIDL2/./index.js"],"names":["root","factory","exports","module","define","amd","this","installedModules","__webpack_require__","moduleId","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","source","position","current","message","kind","level","autofix","sliceTokens","count","slice","Math","max","tokensToText","inputs","precedes","text","map","trivia","join","nextToken","type","length","line","precedingLastLine","splitted","split","lastLine","subsequentTokens","subsequentText","sourceContext","repeat","contextType","context","partial","bareMessage","sourceName","input","tokens","validationError","token","options","index","tokenRe","stringTypes","argumentNameKeywords","nonRegexTerminals","concat","punctuations","idl","str","lastCharIndex","nextChar","charAt","result","test","attemptTokenMatch","noFlushTrivia","currentTrivia","pop","match","includes","punctuation","startsWith","push","Error","re","lastIndex","exec","tokenise","WebIDLParseError","syntaxError","candidates","probe","super","Base","defineProperties","json","undefined","inheritance","proto","descMap","getOwnPropertyDescriptors","entries","getPrototypeOf","idlTypeIncludesDictionary","idlType","defs","union","def","unique","typedefIncludesDictionary","cache","has","set","subtype","type_suffix","tokeniser","obj","nullable","consume","error","single_type","typeName","ret","base","open","return_type","type_with_extended_attributes","keyType","keyIdlType","separator","valueType","close","generic_type","primitive_type","generic","typ","or","union_type","extAttrs","Boolean","prefix","postfix","filter","typedef","target","reference","targetToken","validate","assign","const_value","expression","const_data","negative","ArrayBase","Array","secondaryName","list","rhsType","ids","parser","listName","identifiers","argument_list","hasRhs","params","parse","arg","arguments","extAttr","start_position","optional","variadic","default","unconsume","special","regular","termination","argument","noInherit","readonly","identifier","allowDangler","first","items","item","num_type","integer_type","decimal_type","voidToken","stringifier","autofixAddExposedWindow","exposed","existing","unshift","values","mixin","instance","inheritable","allowedMembers","enableMozillaBodylessInterface","colon","members","ea","mem","args","member","unescape","async","secondTypeRequired","secondTypeAllowed","static_member","console","log","every","opNames","Set","getOperations","op","partials","mixins","mixinMap","ext","additions","forEachExtension","addition","add","existings","checkInterfaceMemberDuplication","required","enableMozillaNamespacesConstants","callback","parseByTokens","interface_","opts","definition","res","eof","concrete","definitions","noop","templates","wrap","extendedAttribute","extendedAttributeReference","write","ast","ts","raw","unescaped","wrapper","reference_token","name_token","type_body","it","firstToken","ref","extended_attributes","default_","data","make_ext_at","id","eats","container","inh","iterate","iterable_like","parent","table","interface","namespace","operation","body","attribute","dictionary","field","const","enum","v","iterable","legacyiterable","maplike","setlike","things","results","thing","dispatch","getMixinMap","all","Map","include","array","validateIterable","duplicates","WeakMap","groupDefinitions","dup","checkDuplicatedNames","flat"],"mappings":"CAAA,SAA2CA,EAAMC,GAC1B,iBAAZC,SAA0C,iBAAXC,OACxCA,OAAOD,QAAUD,IACQ,mBAAXG,QAAyBA,OAAOC,IAC9CD,OAAO,GAAIH,GACe,iBAAZC,QACdA,QAAiB,QAAID,IAErBD,EAAc,QAAIC,IARpB,CASGK,KAAM,WACT,O,YCTE,IAAIC,EAAmB,GAGvB,SAASC,EAAoBC,GAG5B,GAAGF,EAAiBE,GACnB,OAAOF,EAAiBE,GAAUP,QAGnC,IAAIC,EAASI,EAAiBE,GAAY,CACzCC,EAAGD,EACHE,GAAG,EACHT,QAAS,IAUV,OANAU,EAAQH,GAAUI,KAAKV,EAAOD,QAASC,EAAQA,EAAOD,QAASM,GAG/DL,EAAOQ,GAAI,EAGJR,EAAOD,QA0Df,OArDAM,EAAoBM,EAAIF,EAGxBJ,EAAoBO,EAAIR,EAGxBC,EAAoBQ,EAAI,SAASd,EAASe,EAAMC,GAC3CV,EAAoBW,EAAEjB,EAASe,IAClCG,OAAOC,eAAenB,EAASe,EAAM,CAAEK,YAAY,EAAMC,IAAKL,KAKhEV,EAAoBgB,EAAI,SAAStB,GACX,oBAAXuB,QAA0BA,OAAOC,aAC1CN,OAAOC,eAAenB,EAASuB,OAAOC,YAAa,CAAEC,MAAO,WAE7DP,OAAOC,eAAenB,EAAS,aAAc,CAAEyB,OAAO,KAQvDnB,EAAoBoB,EAAI,SAASD,EAAOE,GAEvC,GADU,EAAPA,IAAUF,EAAQnB,EAAoBmB,IAC/B,EAAPE,EAAU,OAAOF,EACpB,GAAW,EAAPE,GAA8B,iBAAVF,GAAsBA,GAASA,EAAMG,WAAY,OAAOH,EAChF,IAAII,EAAKX,OAAOY,OAAO,MAGvB,GAFAxB,EAAoBgB,EAAEO,GACtBX,OAAOC,eAAeU,EAAI,UAAW,CAAET,YAAY,EAAMK,MAAOA,IACtD,EAAPE,GAA4B,iBAATF,EAAmB,IAAI,IAAIM,KAAON,EAAOnB,EAAoBQ,EAAEe,EAAIE,EAAK,SAASA,GAAO,OAAON,EAAMM,IAAQC,KAAK,KAAMD,IAC9I,OAAOF,GAIRvB,EAAoB2B,EAAI,SAAShC,GAChC,IAAIe,EAASf,GAAUA,EAAO2B,WAC7B,WAAwB,OAAO3B,EAAgB,SAC/C,WAA8B,OAAOA,GAEtC,OADAK,EAAoBQ,EAAEE,EAAQ,IAAKA,GAC5BA,GAIRV,EAAoBW,EAAI,SAASiB,EAAQC,GAAY,OAAOjB,OAAOkB,UAAUC,eAAe1B,KAAKuB,EAAQC,IAGzG7B,EAAoBgC,EAAI,GAIjBhC,EAAoBA,EAAoBiC,EAAI,G,+BCjErD,SAAS,EAAMC,EAAQC,EAAUC,EAASC,EAASC,GAAM,MAAEC,EAAQ,QAAO,QAAEC,GAAY,IAItF,SAASC,EAAYC,GACnB,OAAOA,EAAQ,EACbR,EAAOS,MAAMR,EAAUA,EAAWO,GAClCR,EAAOS,MAAMC,KAAKC,IAAIV,EAAWO,EAAO,GAAIP,GAGhD,SAASW,EAAaC,GAAQ,SAAEC,GAAa,IAC3C,MAAMC,EAAOF,EAAOG,IAAI9B,GAAKA,EAAE+B,OAAS/B,EAAED,OAAOiC,KAAK,IAChDC,EAAYnB,EAAOC,GACzB,MAAuB,QAAnBkB,EAAUC,KACLL,EAELD,EACKC,EAAOI,EAAUF,OAEnBF,EAAKN,MAAMU,EAAUF,OAAOI,QAGrC,MACMC,EACsB,QAA1BtB,EAAOC,GAAUmB,KAAiBpB,EAAOC,GAAUqB,KACnDtB,EAAOqB,OAAS,EAAIrB,EAAOC,EAAW,GAAGqB,KACzC,EAEIC,EA1CR,SAAkBR,GAChB,MAAMS,EAAWT,EAAKU,MAAM,MAC5B,OAAOD,EAASA,EAASH,OAAS,GAwCRK,CACxBd,EAAaL,GAPG,GAOsB,CAAEO,UAAU,KAG9Ca,EAAmBpB,EAVP,GAWZqB,EAAiBhB,EAAae,GAI9BE,EAAgBN,EAHMK,EAAeH,MAAM,MAAM,GAGS,MADjD,IAAIK,OAAOP,EAAkBF,QAAU,KAGhDU,EAAuB,WAAT3B,EAAoB,QAAU,SAG5C4B,KAAa5B,mBAAsBkB,IAFpBtB,EAAOzB,YAAcyB,EAAOzB,OAAS,KAC9B2B,GAAWA,EAAQ3B,UAAawD,OAAiB7B,EAAQ+B,QAAU,WAAa,KAAK/B,EAAQkB,QAAQlB,EAAQ3B,SAAW,QAC7DsD,IACvF,MAAO,CACL1B,WAAY6B,KAAW7B,IACvB+B,YAAa/B,EACb6B,UACAV,OACAa,WAAYnC,EAAOzB,KACnB8B,QACAC,UACA8B,MAAOR,EACPS,OAAQV,GAeL,SAASW,EAAgBtC,EAAQuC,EAAOrC,EAASC,EAASqC,GAC/D,OAAO,EAAMxC,EAAQuC,EAAME,MAAOvC,EAASC,EAAS,aAAcqC,G,OCjFpE,MAAME,EAAU,CAGd,QAAW,sGACX,QAAW,8CACX,WAAc,+BACd,OAAU,WACV,WAAc,cACd,QAAW,iDACX,MAAS,wBAGEC,EAAc,CACzB,aACA,YACA,aAGWC,EAAuB,CAClC,QACA,YACA,WACA,QACA,UACA,aACA,OACA,SACA,WACA,UACA,YACA,WACA,UACA,YACA,UACA,WACA,UACA,SACA,SACA,cACA,UACA,gBAGIC,EAAoB,CACxB,YACA,cACA,WACA,MACA,UACA,QACA,UACA,OACA,SACA,QACA,QACA,OACA,QACA,OACA,QACA,WACA,KACA,WACA,SACA,WACA,QACA,OACA,WACA,QACAC,OAAOF,EAAsBD,GAEzBI,EAAe,CACnB,IACA,IACA,IACA,MACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,KA6FK,MAAM,EAIX,YAAYC,GACVpF,KAAKoC,OA5FT,SAAkBiD,GAChB,MAAMZ,EAAS,GACf,IAAIa,EAAgB,EAChBjC,EAAS,GACTK,EAAO,EACPmB,EAAQ,EACZ,KAAOS,EAAgBD,EAAI5B,QAAQ,CACjC,MAAM8B,EAAWF,EAAIG,OAAOF,GAC5B,IAAIG,GAAU,EAQd,GANI,YAAYC,KAAKH,GACnBE,EAASE,EAAkB,aAAc,CAAEC,eAAe,IACpC,MAAbL,IACTE,EAASE,EAAkB,UAAW,CAAEC,eAAe,MAGzC,IAAZH,EAAe,CACjB,MAAMI,EAAgBpB,EAAOqB,MAAMzE,MACnCqC,IAASmC,EAAcE,MAAM,QAAU,IAAItC,OAC3CJ,GAAUwC,EACVhB,GAAS,OACJ,GAAI,iBAAiBa,KAAKH,IAK/B,IAHgB,KADhBE,EAASE,EAAkB,cAEzBF,EAASE,EAAkB,aAEb,IAAZF,EAAe,CACjBA,EAASE,EAAkB,cAC3B,MAAMhB,EAAQF,EAAOA,EAAOhB,OAAS,IACrB,IAAZgC,GAAiBR,EAAkBe,SAASrB,EAAMtD,SACpDsD,EAAMnB,KAAOmB,EAAMtD,YAGD,MAAbkE,IACTE,EAASE,EAAkB,WAG7B,IAAK,MAAMM,KAAed,EACxB,GAAIE,EAAIa,WAAWD,EAAaX,GAAgB,CAC9Cb,EAAO0B,KAAK,CAAE3C,KAAMyC,EAAa5E,MAAO4E,EAAa5C,SAAQK,OAAMmB,UACnExB,EAAS,GAEToC,EADAH,GAAiBW,EAAYxC,OAE7B,MAQJ,IAHgB,IAAZgC,IACFA,EAASE,EAAkB,WAEb,IAAZF,EACF,MAAM,IAAIW,MAAM,gCAElBd,EAAgBG,EAChBZ,GAAS,EAUX,OANAJ,EAAO0B,KAAK,CACV3C,KAAM,MACNnC,MAAO,GACPgC,WAGKoB,EAOP,SAASkB,EAAkBnC,GAAM,cAAEoC,GAAkB,IACnD,MAAMS,EAAKvB,EAAQtB,GACnB6C,EAAGC,UAAYhB,EACf,MAAMG,EAASY,EAAGE,KAAKlB,GACvB,OAAII,GACFhB,EAAO0B,KAAK,CAAE3C,OAAMnC,MAAOoE,EAAO,GAAIpC,SAAQK,OAAMmB,UAC/Ce,IACHvC,EAAS,IAEJgD,EAAGC,YAEJ,GASME,CAASpB,GACvBpF,KAAKqC,SAAW,EAMlB,MAAME,GACJ,MAAM,IAAIkE,EDtHP,SAAqBrE,EAAQC,EAAUC,EAASC,GACrD,OAAO,EAAMH,EAAQC,EAAUC,EAASC,EAAS,UCqHpBmE,CAAY1G,KAAKoC,OAAQpC,KAAKqC,SAAUrC,KAAKsC,QAASC,IAMnF,MAAMiB,GACJ,OAAOxD,KAAKoC,OAAOqB,OAASzD,KAAKqC,UAAYrC,KAAKoC,OAAOpC,KAAKqC,UAAUmB,OAASA,EAMnF,WAAWmD,GACT,IAAK,MAAMnD,KAAQmD,EAAY,CAC7B,IAAK3G,KAAK4G,MAAMpD,GAAO,SACvB,MAAMmB,EAAQ3E,KAAKoC,OAAOpC,KAAKqC,UAE/B,OADArC,KAAKqC,WACEsC,GAOX,UAAUtC,GACRrC,KAAKqC,SAAWA,GAIpB,MAAMoE,UAAyBL,MAC7B,aAAY,QAAE7D,EAAO,YAAE+B,EAAW,QAAEF,EAAO,KAAEV,EAAI,WAAEa,EAAU,MAAEC,EAAK,OAAEC,IACpEoC,MAAMtE,GAENvC,KAAKW,KAAO,mBACZX,KAAKsE,YAAcA,EACnBtE,KAAKoE,QAAUA,EACfpE,KAAK0D,KAAOA,EACZ1D,KAAKuE,WAAaA,EAClBvE,KAAKwE,MAAQA,EACbxE,KAAKyE,OAASA,GC1OX,MAAMqC,EACX,aAAY,OAAE1E,EAAM,OAAEqC,IACpB3D,OAAOiG,iBAAiB/G,KAAM,CAC5BoC,OAAQ,CAAEf,MAAOe,GACjBqC,OAAQ,CAAEpD,MAAOoD,KAIrB,SACE,MAAMuC,EAAO,CAAExD,UAAMyD,EAAWtG,UAAMsG,EAAWC,iBAAaD,GAC9D,IAAIE,EAAQnH,KACZ,KAAOmH,IAAUrG,OAAOkB,WAAW,CACjC,MAAMoF,EAAUtG,OAAOuG,0BAA0BF,GACjD,IAAK,MAAOxF,EAAKN,KAAUP,OAAOwG,QAAQF,IACpC/F,EAAML,YAAcK,EAAMJ,OAC5B+F,EAAKrF,GAAO3B,KAAK2B,IAGrBwF,EAAQrG,OAAOyG,eAAeJ,GAEhC,OAAOH,GCLJ,SAASQ,EAA0BC,EAASC,GACjD,IAAKD,EAAQE,MAAO,CAClB,MAAMC,EAAMF,EAAKG,OAAO5G,IAAIwG,EAAQA,SACpC,IAAKG,EACH,OAEF,GAAiB,YAAbA,EAAIpE,KAAoB,CAC1B,MAAM,0BAAEsE,GAA6BJ,EAAKK,MAC1C,GAAID,EAA0BE,IAAIJ,GAGhC,OAAOE,EAA0B7G,IAAI2G,GAEvCF,EAAKK,MAAMD,0BAA0BG,IAAIL,OAAKX,GAC9C,MAAMxB,EAAS+B,EAA0BI,EAAIH,QAASC,GAEtD,GADAA,EAAKK,MAAMD,0BAA0BG,IAAIL,EAAKnC,GAC1CA,EACF,OAAOgC,EAGX,GAAiB,eAAbG,EAAIpE,KACN,OAAOiE,EAGX,IAAK,MAAMS,KAAWT,EAAQS,QAAS,CACrC,MAAMzC,EAAS+B,EAA0BU,EAASR,GAClD,GAAIjC,EACF,OAAIyC,EAAQP,MACHlC,EAEFyC,GCIb,SAASC,EAAYC,EAAWC,GAC9B,MAAMC,EAAWF,EAAUG,QAAQ,KAC/BD,IACFD,EAAI5D,OAAO6D,SAAWA,GAEpBF,EAAUxB,MAAM,MAAMwB,EAAUI,MAAM,iCAO5C,SAASC,EAAYL,EAAWM,GAC9B,IAAIC,EApDN,SAAsBP,EAAWM,GAC/B,MAAME,EAAOR,EAAUG,QAAQ,cAAe,UAAW,WAAY,UACrE,IAAKK,EACH,OAEF,MAAMD,EAAM,IAAI,EAAK,CAAEvG,OAAQgG,EAAUhG,OAAQqC,OAAQ,CAAEmE,UAE3D,OADAD,EAAIlE,OAAOoE,KAAOT,EAAUG,QAAQ,MAAQH,EAAUI,kCAAkCI,EAAKpF,QACrFoF,EAAKpF,MACX,IAAK,UAAW,CACV4E,EAAUxB,MAAM,MAAMwB,EAAUI,MAAM,+CAC1C,MAAMN,EAAUY,EAAYV,EAAWM,IAAaN,EAAUI,MAAM,2BACpEG,EAAIT,QAAQ/B,KAAK+B,GACjB,MAEF,IAAK,WACL,IAAK,cAAe,CAClB,MAAMA,EAAUa,EAA8BX,EAAWM,IAAaN,EAAUI,iBAAiBI,EAAKpF,gBACtGmF,EAAIT,QAAQ/B,KAAK+B,GACjB,MAEF,IAAK,SAAU,CACTE,EAAUxB,MAAM,MAAMwB,EAAUI,MAAM,6CAC1C,MAAMQ,EAAUZ,EAAUG,WAAWxD,IAAgBqD,EAAUI,oCAAoCzD,EAAYzB,KAAK,SAC9G2F,EAAa,IAAI,EAAK,CAAE7G,OAAQgG,EAAUhG,OAAQqC,OAAQ,CAAEmE,KAAMI,KACxEC,EAAWxE,OAAOyE,UAAYd,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,uCACxES,EAAWzF,KAAOkF,EAClB,MAAMS,EAAYJ,EAA8BX,EAAWM,IAAaN,EAAUI,MAAM,qCACxFG,EAAIT,QAAQ/B,KAAK8C,EAAYE,GAC7B,OAKJ,OAFKR,EAAIlB,SAASW,EAAUI,oCAAoCI,EAAKpF,QACrEmF,EAAIlE,OAAO2E,MAAQhB,EAAUG,QAAQ,MAAQH,EAAUI,uCAAuCI,EAAKpF,QAC5FmF,EAmBGU,CAAajB,EAAWM,IAAaY,EAAelB,GAC9D,IAAKO,EAAK,CACR,MAAMC,EAAOR,EAAUG,QAAQ,gBAAiBxD,GAChD,IAAK6D,EACH,OAEFD,EAAM,IAAI,EAAK,CAAEvG,OAAQgG,EAAUhG,OAAQqC,OAAQ,CAAEmE,UACjDR,EAAUxB,MAAM,MAAMwB,EAAUI,kCAAkCI,EAAKvH,SAQ7E,MANoB,YAAhBsH,EAAIY,SAAyBnB,EAAUxB,MAAM,MAC/CwB,EAAUI,MAAM,mCAElBG,EAAInF,KAAOkF,GAAY,KACvBP,EAAYC,EAAWO,GACnBA,EAAIL,UAA4B,QAAhBK,EAAIlB,SAAmBW,EAAUI,MAAM,sCACpDG,EA+BF,MAAM,UAAa7B,EAKxB,aAAasB,EAAWM,GACtB,OAAOD,EAAYL,EAAWM,IA9BlC,SAAoBN,EAAW5E,GAC7B,MAAMiB,EAAS,GAEf,GADAA,EAAOoE,KAAOT,EAAUG,QAAQ,MAC3B9D,EAAOoE,KAAM,OAClB,MAAMF,EAAM,IAAI,EAAK,CAAEvG,OAAQgG,EAAUhG,OAAQqC,WAEjD,IADAkE,EAAInF,KAAOA,GAAQ,OACN,CACX,MAAMgG,EAAMT,EAA8BX,IAAcA,EAAUI,MAAM,wDACpD,QAAhBgB,EAAI/B,SAAmBW,EAAUI,MAAM,iDAC3CG,EAAIT,QAAQ/B,KAAKqD,GACjB,MAAMC,EAAKrB,EAAUG,QAAQ,MAC7B,IAAIkB,EAGC,MAFHD,EAAI/E,OAAOyE,UAAYO,EAS3B,OALId,EAAIlB,QAAQhE,OAAS,GACvB2E,EAAUI,MAAM,kEAElB/D,EAAO2E,MAAQhB,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,2BACzDL,EAAYC,EAAWO,GAChBA,EASsCe,CAAWtB,EAAWM,GAGnE,aAAY,OAAEtG,EAAM,OAAEqC,IACpBoC,MAAM,CAAEzE,SAAQqC,WAChB3D,OAAOC,eAAef,KAAM,UAAW,CAAEqB,MAAO,KAChDrB,KAAK2J,SAAW,GAGlB,cACE,OAAI3J,KAAKkI,QAAQzE,QAAUzD,KAAKyE,OAAOmE,KAC9B5I,KAAKyE,OAAOmE,KAAKvH,MAEnB,GAET,eACE,OAAOuI,QAAQ5J,KAAKyE,OAAO6D,UAE7B,YACE,OAAOsB,QAAQ5J,KAAKkI,QAAQzE,UAAYzD,KAAKyE,OAAOmE,KAEtD,cACE,GAAI5I,KAAKkI,QAAQzE,OACf,OAAOzD,KAAKkI,QAQd,OAAO,EALM,CACXlI,KAAKyE,OAAOoF,OACZ7J,KAAKyE,OAAOmE,KACZ5I,KAAKyE,OAAOqF,SACZC,OAAOzI,GAAKA,GAAG8B,IAAI9B,GAAKA,EAAED,OAAOiC,KAAK,MAI1C,UAAUoE,GAKR,MAAMsC,GAAWhK,KAAK2H,OAASD,EAAKG,OAAO5G,IAAIjB,KAAKyH,SAC9CwC,EACJjK,KAAK2H,MAAQ3H,KACZgK,GAA4B,YAAjBA,EAAQxG,KAAsBwG,EAAQvC,aAClDR,EACF,GAAIgD,GAAUjK,KAAKsI,SAAU,CAE3B,MAAM4B,EAAY1C,EAA0ByC,EAAQvC,GACpD,GAAIwC,EAAW,CACb,MAAMC,GAAenK,KAAK2H,MAAQuC,EAAYlK,MAAMyE,OAAOmE,KACrDrG,EAAU,wDACVmC,EAAgB1E,KAAKoC,OAAQ+H,EAAanK,KAAMuC,SAIxD,IAAK,MAAM2F,KAAWlI,KAAKkI,cAClBA,EAAQkC,SAAS1C,ICtKzB,MAAM,UAAgBZ,EAI3B,aAAasB,GACX,MAAMiC,EAASjC,EAAUG,QAAQ,KACjC,IAAK8B,EACH,OAAO,KAET,MAAMzC,EAAM0C,EAAYlC,IAAcA,EAAUG,QAAQ,SAAU,OAAQ,IAAK,MAAQH,EAAUI,MAAM,wBACjG+B,EAAa,CAAC3C,GACpB,GAAiB,MAAbA,EAAIpE,KAAc,CACpB,MAAM4F,EAAQhB,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,wCACxD+B,EAAWpE,KAAKiD,QACX,GAAiB,MAAbxB,EAAIpE,KAAc,CAC3B,MAAM4F,EAAQhB,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,0CACxD+B,EAAWpE,KAAKiD,GAElB,OAAO,IAAI,EAAQ,CAAEhH,OAAQgG,EAAUhG,OAAQqC,OAAQ,CAAE4F,UAAUE,eAGrE,aAAY,OAAEnI,EAAM,OAAEqC,EAAM,WAAE8F,IAC5B1D,MAAM,CAAEzE,SAAQqC,WAChB3D,OAAOC,eAAef,KAAM,aAAc,CAAEqB,MAAOkJ,IAGrD,WACE,OAAOC,EAAWxK,KAAKuK,WAAW,IAAI/G,KAExC,YACE,OAAOgH,EAAWxK,KAAKuK,WAAW,IAAIlJ,MAExC,eACE,OAAOmJ,EAAWxK,KAAKuK,WAAW,IAAIE,UCpCnC,MAAMC,UAAkBC,MAC7B,aAAY,OAAEvI,EAAM,OAAEqC,IACpBoC,QACA/F,OAAOiG,iBAAiB/G,KAAM,CAC5BoC,OAAQ,CAAEf,MAAOe,GACjBqC,OAAQ,CAAEpD,MAAOoD,MCAvB,MAAM,UAAoCqC,EAIxC,aAAasB,GACX,MAAM3D,EAAS,CAAE4F,OAAQjC,EAAUG,QAAQ,MACrCI,EAAM,IAAI,EAA4B,CAAEvG,OAAQgG,EAAUhG,OAAQqC,WAexE,OAdIA,EAAO4F,SACT5F,EAAOmG,cAAgBxC,EAAUG,QAAQ,aAAc,UAAW,UAAW,WAE/E9D,EAAOoE,KAAOT,EAAUG,QAAQ,KAC5B9D,EAAOoE,MACTF,EAAIkC,KAAuB,oBAAhBlC,EAAImC,QCiGd,SAAqB1C,GAC1B,MAAM2C,EAAMF,EAAKzC,EAAW,CAAE4C,OAAQ,EAAMA,OAAO5C,EAAW,cAAe6C,SAAU,oBAClFF,EAAItH,QACP2E,EAAUI,MAAM,uCAElB,OAAOuC,EDpGDG,CAAY9C,GAEZ+C,EAAc/C,GAChB3D,EAAO2E,MAAQhB,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,yDAChDG,EAAIyC,SAAW3G,EAAOmG,eAC/BxC,EAAUI,MAAM,uDAEXG,EAGT,cACE,OAAQ3I,KAAKyE,OAAO4F,OACjBrK,KAAKyE,OAAOmG,cACX5K,KAAKyE,OAAOmG,cAAcpH,KADC,kBADF,MAM1B,MAAM,UAAgCsD,EAI3C,aAAasB,GACX,MAAMzH,EAAOyH,EAAUG,QAAQ,cAC/B,GAAI5H,EACF,OAAO,IAAI,EAAwB,CACjCyB,OAAQgG,EAAUhG,OAClBqC,OAAQ,CAAE9D,QACV0K,OAAQ,EAA4BC,MAAMlD,KAKhD,aAAY,OAAEhG,EAAM,OAAEqC,EAAM,OAAE4G,IAC5BxE,MAAM,CAAEzE,SAAQqC,WAChB3D,OAAOC,eAAef,KAAM,SAAU,CAAEqB,MAAOgK,IAGjD,WACE,MAAO,qBAET,WACE,OAAOrL,KAAKyE,OAAO9D,KAAKU,MAE1B,UACE,MAAQyJ,QAAStH,EAAI,OAAEiB,EAAM,KAAEoG,GAAS7K,KAAKqL,OAC7C,OAAK7H,EAIE,CAAEA,OAAMnC,MADQ,oBAATmC,EAA6BqH,EAAOpG,EAAOmG,cAAcvJ,OAF9D,KAKX,gBACE,MAAM,QAAEyJ,EAAO,KAAED,GAAS7K,KAAKqL,OAC/B,OAAKR,GAAoB,oBAAZC,EAGND,EAFE,GAKX,UAAUnD,GACR,GAAkB,sBAAd1H,KAAKW,KAA8B,CACrC,MAAM4B,EAAU,gOAIVmC,EAAgB1E,KAAKoC,OAAQpC,KAAKyE,OAAO9D,KAAMX,KAAMuC,EAAS,CAAEE,MAAO,YAE/E,IAAK,MAAM8I,KAAOvL,KAAKwL,gBACdD,EAAInB,SAAS1C,IAOnB,MAAM,UAA2BgD,EAItC,aAAatC,GACX,MAAM3D,EAAS,GAEf,GADAA,EAAOoE,KAAOT,EAAUG,QAAQ,MAC3B9D,EAAOoE,KAAM,OAAO,IAAI,EAAmB,IAChD,MAAMF,EAAM,IAAI,EAAmB,CAAEvG,OAAQgG,EAAUhG,OAAQqC,WAY/D,OAXAkE,EAAIxC,QAAQ0E,EAAKzC,EAAW,CAC1B4C,OAAQ,EAAwBM,MAChCL,SAAU,wBAEZxG,EAAO2E,MAAQhB,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,kDACpDG,EAAIlF,QACP2E,EAAUI,MAAM,qCAEdJ,EAAUxB,MAAM,MAClBwB,EAAUI,MAAM,kEAEXG,EAGT,UAAUjB,GACR,IAAK,MAAM+D,KAAWzL,WACbyL,EAAQrB,SAAS1C,IE/GvB,MAAM,UAAiBZ,EAI5B,aAAasB,GACX,MAAMsD,EAAiBtD,EAAU/F,SAC3BoC,EAAS,GACTkE,EAAM,IAAI,EAAS,CAAEvG,OAAQgG,EAAUhG,OAAQqC,WAIrD,OAHAkE,EAAIgB,SAAW,EAAmB2B,MAAMlD,GACxC3D,EAAOkH,SAAWvD,EAAUG,QAAQ,YACpCI,EAAIlB,QAAUsB,EAA8BX,EAAW,iBAClDO,EAAIlB,SAGJhD,EAAOkH,WACVlH,EAAOmH,SAAWxD,EAAUG,QAAQ,QAEtC9D,EAAO9D,KAAOyH,EAAUG,QAAQ,gBAAiBvD,GAC5CP,EAAO9D,MAGZgI,EAAIkD,QAAUpH,EAAOkH,SAAW,EAAQL,MAAMlD,GAAa,KACpDO,GAHEP,EAAU0D,UAAUJ,IAPpBtD,EAAU0D,UAAUJ,GAa/B,WACE,MAAO,WAET,eACE,QAAS1L,KAAKyE,OAAOkH,SAEvB,eACE,QAAS3L,KAAKyE,OAAOmH,SAEvB,WACE,OAAO,EAAS5L,KAAKyE,OAAO9D,KAAKU,OAGnC,UAAUqG,GAER,SADO1H,KAAKyH,QAAQ2C,SAAS1C,GACzBF,EAA0BxH,KAAKyH,QAASC,GAAO,CACjD,GAAI1H,KAAK2L,WAAa3L,KAAK6L,QAAS,CAClC,MAAMtJ,EAAU,yEACVmC,EAAgB1E,KAAKoC,OAAQpC,KAAKyE,OAAO9D,KAAMX,KAAMuC,EAAS,CAClEG,SAcqC6I,EAdUvL,KAehD,KACLuL,EAAIM,QAAU,EAAQP,MAAM,IAAI,EAAU,cAbxC,GAAItL,KAAKyH,QAAQa,SAAU,CACzB,MAAM/F,EAAU,iDACVmC,EAAgB1E,KAAKoC,OAAQpC,KAAKyE,OAAO9D,KAAMX,KAAMuC,IASnE,IAA+CgJ,GChExC,MAAM,UAAczE,EAKzB,cAAcsB,EAAW5E,GACvB,MAAO,KACL,MAAMnC,EAAQ+G,EAAUG,QAAQ/E,GAChC,GAAInC,EACF,OAAO,IAAI,EAAM,CAAEe,OAAQgG,EAAUhG,OAAQqC,OAAQ,CAAEpD,YAK7D,YACE,OAAOrB,KAAKyE,OAAOpD,MAAMA,OCdtB,MAAM,UAAkByF,EAI7B,aAAasB,GAAW,QAAE2D,EAAO,QAAEC,GAAY,IAC7C,MAAMvH,EAAS,CAAEsH,WACXpD,EAAM,IAAI,EAAU,CAAEvG,OAAQgG,EAAUhG,OAAQqC,WACtD,OAAIsH,GAA6B,gBAAlBA,EAAQ1K,QACrBoD,EAAOwH,YAAc7D,EAAUG,QAAQ,KACnC9D,EAAOwH,cACTtD,EAAI6C,UAAY,GACT7C,IAGNoD,GAAYC,IACfvH,EAAOsH,QAAU3D,EAAUG,QAAQ,SAAU,SAAU,YAEzDI,EAAIlB,QAAUqB,EAAYV,IAAcA,EAAUI,MAAM,uBACxD/D,EAAO9D,KAAOyH,EAAUG,QAAQ,aAAc,YAC9C9D,EAAOoE,KAAOT,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,qBACxDG,EAAI6C,UAAYL,EAAc/C,GAC9B3D,EAAO2E,MAAQhB,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,0BACzD/D,EAAOwH,YAAc7D,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,wCACxDG,GAGT,WACE,MAAO,YAET,WACE,MAAM,KAAEhI,GAASX,KAAKyE,OACtB,OAAK9D,EAGE,EAASA,EAAKU,OAFZ,GAIX,cACE,OAAKrB,KAAKyE,OAAOsH,QAGV/L,KAAKyE,OAAOsH,QAAQ1K,MAFlB,GAKX,UAAUqG,GACJ1H,KAAKyH,gBACAzH,KAAKyH,QAAQ2C,SAAS1C,IAE/B,IAAK,MAAMwE,KAAYlM,KAAKwL,gBACnBU,EAAS9B,SAAS1C,IChDxB,MAAM,UAAkBZ,EAI7B,aAAasB,GAAW,QAAE2D,EAAO,UAAEI,GAAY,EAAK,SAAEC,GAAW,GAAU,IACzE,MAAMV,EAAiBtD,EAAU/F,SAC3BoC,EAAS,CAAEsH,WACXpD,EAAM,IAAI,EAAU,CAAEvG,OAAQgG,EAAUhG,OAAQqC,WAYtD,GAXKsH,GAAYI,IACf1H,EAAOsH,QAAU3D,EAAUG,QAAQ,YAEjB,YAAhBI,EAAIoD,SAAyB3D,EAAUxB,MAAM,aAC/CwB,EAAUI,MAAM,4CAElB/D,EAAO2H,SAAWhE,EAAUG,QAAQ,YAChC6D,IAAa3H,EAAO2H,UAAYhE,EAAUxB,MAAM,cAClDwB,EAAUI,MAAM,+CAElB/D,EAAOmE,KAAOR,EAAUG,QAAQ,aAC3B9D,EAAOmE,KAAZ,CAKA,OADAD,EAAIlB,QAAUsB,EAA8BX,EAAW,mBAAqBA,EAAUI,MAAM,0BACpFG,EAAIlB,QAAQ8B,SAClB,IAAK,WACL,IAAK,SAAUnB,EAAUI,kCAAkCG,EAAIlB,QAAQ8B,iBAIzE,OAFA9E,EAAO9D,KAAOyH,EAAUG,QAAQ,aAAc,QAAS,aAAeH,EAAUI,MAAM,0BACtF/D,EAAOwH,YAAc7D,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,wCACxDG,EAVLP,EAAU0D,UAAUJ,GAaxB,WACE,MAAO,YAET,cACE,OAAK1L,KAAKyE,OAAOsH,QAGV/L,KAAKyE,OAAOsH,QAAQ1K,MAFlB,GAIX,eACE,QAASrB,KAAKyE,OAAO2H,SAEvB,WACE,OAAO,EAASpM,KAAKyE,OAAO9D,KAAKU,OAGnC,UAAUqG,SACD1H,KAAKyH,QAAQ2C,SAAS1C,IJ1C1B,SAAS,EAAS2E,GACvB,OAAOA,EAAWnG,WAAW,KAAOmG,EAAWxJ,MAAM,GAAKwJ,EAWrD,SAASxB,EAAKzC,GAAW,OAAE4C,EAAM,aAAEsB,EAAY,SAAErB,EAAW,SACjE,MAAMsB,EAAQvB,EAAO5C,GACrB,IAAKmE,EACH,MAAO,GAETA,EAAM9H,OAAOyE,UAAYd,EAAUG,QAAQ,KAC3C,MAAMiE,EAAQ,CAACD,GACf,KAAOA,EAAM9H,OAAOyE,WAAW,CAC7B,MAAMuD,EAAOzB,EAAO5C,GACpB,IAAKqE,EAAM,CACJH,GACHlE,EAAUI,2BAA2ByC,KAEvC,MAIF,GAFAwB,EAAKhI,OAAOyE,UAAYd,EAAUG,QAAQ,KAC1CiE,EAAMrG,KAAKsG,IACNA,EAAKhI,OAAOyE,UAAW,MAE9B,OAAOsD,EAMF,SAASlC,EAAYlC,GAC1B,OAAOA,EAAUG,QAAQ,OAAQ,QAAS,WAAY,YAAa,MAAO,UAAW,WAQhF,SAASiC,GAAW,KAAEhH,EAAI,MAAEnC,IACjC,OAAQmC,GACN,IAAK,OACL,IAAK,QACH,MAAO,CAAEA,KAAM,UAAWnC,MAAgB,SAATmC,GACnC,IAAK,WACL,IAAK,YACH,MAAO,CAAEA,KAAM,WAAYiH,SAAUjH,EAAK0C,WAAW,MACvD,IAAK,IACH,MAAO,CAAE1C,KAAM,WAAYnC,MAAO,IACpC,IAAK,IACH,MAAO,CAAEmC,KAAM,cACjB,IAAK,UACL,IAAK,UACH,MAAO,CAAEA,KAAM,SAAUnC,SAC3B,IAAK,SACH,MAAO,CAAEmC,KAAM,SAAUnC,MAAOA,EAAMwB,MAAM,GAAI,IAClD,QACE,MAAO,CAAEW,SAOR,SAAS8F,EAAelB,GAoB7B,MAAM,OAAEhG,GAAWgG,EACbsE,EApBN,WACE,MAAM7C,EAASzB,EAAUG,QAAQ,YAC3BK,EAAOR,EAAUG,QAAQ,QAAS,QACxC,GAAIK,EAAM,CACR,MAAMkB,EAAU1B,EAAUG,QAAQ,QAClC,OAAO,IAAI,EAAK,CAAEnG,SAAQqC,OAAQ,CAAEoF,SAAQjB,OAAMkB,aAEhDD,GAAQzB,EAAUI,MAAM,gCAabmE,IAVjB,WACE,MAAM9C,EAASzB,EAAUG,QAAQ,gBAC3BK,EAAOR,EAAUG,QAAQ,QAAS,UACxC,GAAIK,EACF,OAAO,IAAI,EAAK,CAAExG,SAAQqC,OAAQ,CAAEoF,SAAQjB,UAE1CiB,GAAQzB,EAAUI,MAAM,8BAIcoE,GAC5C,GAAIF,EAAU,OAAOA,EACrB,MAAM9D,EAAOR,EAAUG,QAAQ,UAAW,OAAQ,SAClD,OAAIK,EACK,IAAI,EAAK,CAAExG,SAAQqC,OAAQ,CAAEmE,eADtC,EAmBK,SAASuC,EAAc/C,GAC5B,OAAOyC,EAAKzC,EAAW,CAAE4C,OAAQ,EAASM,MAAOL,SAAU,mBAOtD,SAASlC,EAA8BX,EAAWM,GACvD,MAAMiB,EAAW,EAAmB2B,MAAMlD,GACpCO,EAAM,EAAK2C,MAAMlD,EAAWM,GAElC,OADIC,IAAKA,EAAIgB,SAAWA,GACjBhB,EAOF,SAASG,EAAYV,EAAWM,GACrC,MAAMc,EAAM,EAAK8B,MAAMlD,EAAWM,GAAY,eAC9C,GAAIc,EACF,OAAOA,EAET,MAAMqD,EAAYzE,EAAUG,QAAQ,QACpC,GAAIsE,EAAW,CACb,MAAMlE,EAAM,IAAI,EAAK,CAAEvG,OAAQgG,EAAUhG,OAAQqC,OAAQ,CAAEmE,KAAMiE,KAEjE,OADAlE,EAAInF,KAAO,cACJmF,GAOJ,SAASmE,EAAY1E,GAC1B,MAAM2D,EAAU3D,EAAUG,QAAQ,eAClC,GAAKwD,EAIL,OAHe,EAAUT,MAAMlD,EAAW,CAAE2D,aAC1C,EAAUT,MAAMlD,EAAW,CAAE2D,aAC7B3D,EAAUI,MAAM,4BAQb,SAASuE,EAAwBnF,GACtC,MAAO,KACL,GAAIA,EAAI+B,SAASlG,OAAO,CACtB,MAAM2E,EAAY,IAAI,EAAU,mBAC1B4E,EAAU,EAAwB1B,MAAMlD,GAC9C4E,EAAQvI,OAAOyE,UAAYd,EAAUG,QAAQ,KAC7C,MAAM0E,EAAWrF,EAAI+B,SAAS,GACzB,MAAMjE,KAAKuH,EAASxI,OAAO9D,KAAK0C,UACnC4J,EAASxI,OAAO9D,KAAK0C,WAAa4J,EAASxI,OAAO9D,KAAK0C,UAEzDuE,EAAI+B,SAASuD,QAAQF,QAErBpF,EAAI+B,SAAW,EAAmB2B,MAAM,IAAI,EAAU,qBACtD1D,EAAI+B,SAASlF,OAAOoE,KAAKxF,OAASuE,EAAInD,OAAOmE,KAAKvF,OAClDuE,EAAInD,OAAOmE,KAAKvF,OAAS,KKvL/B,MAAM,UAAkB,EAItB,aAAa+E,GACX,MAAM/G,EAAQ+G,EAAUG,QAAQ,UAChC,GAAIlH,EACF,OAAO,IAAI,EAAU,CAAEe,OAAQgG,EAAUhG,OAAQqC,OAAQ,CAAEpD,WAI/D,WACE,MAAO,aAET,YACE,OAAOwF,MAAMxF,MAAMwB,MAAM,GAAI,IAI1B,MAAM,UAAaiE,EAIxB,aAAasB,GACX,MAAM3D,EAAS,GAEf,GADAA,EAAOmE,KAAOR,EAAUG,QAAQ,SAC3B9D,EAAOmE,KACV,OAEFnE,EAAO9D,KAAOyH,EAAUG,QAAQ,eAAiBH,EAAUI,MAAM,oBACjE,MAAMG,EAAMP,EAAU9F,QAAU,IAAI,EAAK,CAAEF,OAAQgG,EAAUhG,OAAQqC,WAerE,OAdAA,EAAOoE,KAAOT,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,iBACxDG,EAAIwE,OAAStC,EAAKzC,EAAW,CAC3B4C,OAAQ,EAAUM,MAClBgB,cAAc,EACdrB,SAAU,gBAER7C,EAAUxB,MAAM,WAClBwB,EAAUI,MAAM,gCAElB/D,EAAO2E,MAAQhB,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,4BACpDG,EAAIwE,OAAO1J,QACd2E,EAAUI,MAAM,oBAElB/D,EAAOwH,YAAc7D,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,2BACxDG,EAGT,WACE,MAAO,OAET,WACE,OAAO,EAAS3I,KAAKyE,OAAO9D,KAAKU,QCrD9B,MAAM,UAAiByF,EAI5B,aAAasB,GACX,MAAM6B,EAAS7B,EAAUG,QAAQ,cACjC,IAAK0B,EACH,OAEF,MAAMxF,EAAS,CAAEwF,UAEjB,GADAxF,EAAOuB,SAAWoC,EAAUG,QAAQ,YAC/B9D,EAAOuB,SAMZ,OAFAvB,EAAO2I,MAAQhF,EAAUG,QAAQ,eAAiBH,EAAUI,MAAM,iCAClE/D,EAAOwH,YAAc7D,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,2CACxD,IAAI,EAAS,CAAEpG,OAAQgG,EAAUhG,OAAQqC,WAL9C2D,EAAU0D,UAAU7B,EAAOpF,OAQ/B,WACE,MAAO,WAET,aACE,OAAO,EAAS7E,KAAKyE,OAAOwF,OAAO5I,OAErC,eACE,OAAO,EAASrB,KAAKyE,OAAO2I,MAAM/L,QC3B/B,MAAM,UAAgByF,EAI3B,aAAasB,GACX,MAAM3D,EAAS,GACTkE,EAAM,IAAI,EAAQ,CAAEvG,OAAQgG,EAAUhG,OAAQqC,WAEpD,GADAA,EAAOmE,KAAOR,EAAUG,QAAQ,WAC3B9D,EAAOmE,KAOZ,OAJAD,EAAIlB,QAAUsB,EAA8BX,EAAW,iBAAmBA,EAAUI,MAAM,wBAC1F/D,EAAO9D,KAAOyH,EAAUG,QAAQ,eAAiBH,EAAUI,MAAM,wBACjEJ,EAAU9F,QAAUqG,EACpBlE,EAAOwH,YAAc7D,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,sCACxDG,EAGT,WACE,MAAO,UAET,WACE,OAAO,EAAS3I,KAAKyE,OAAO9D,KAAKU,OAGnC,UAAUqG,SACD1H,KAAKyH,QAAQ2C,SAAS1C,IC1B1B,MAAM,UAAyBZ,EAIpC,aAAasB,EAAWQ,GACtB,MAAMnE,EAAS,CAAEmE,QACXD,EAAM,IAAI,EAAiB,CAAEvG,OAAQgG,EAAUhG,OAAQqC,WAS7D,OARAA,EAAO9D,KAAOyH,EAAUG,QAAQ,eAAiBH,EAAUI,MAAM,yBACjEJ,EAAU9F,QAAUqG,EACpBlE,EAAO4F,OAASjC,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,gCAC1DG,EAAIlB,QAAUqB,EAAYV,IAAcA,EAAUI,MAAM,gCACxD/D,EAAOoE,KAAOT,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,4CACxDG,EAAI6C,UAAYL,EAAc/C,GAC9B3D,EAAO2E,MAAQhB,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,yBACzD/D,EAAOwH,YAAc7D,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,uCACxDG,EAGT,WACE,MAAO,WAET,WACE,OAAO,EAAS3I,KAAKyE,OAAO9D,KAAKU,OAGnC,UAAUqG,SACD1H,KAAKyH,QAAQ2C,SAAS1C,ICb1B,MAAM,UAAkBZ,EAO3B,aAAasB,EAAWiF,GAAU,KAAE7J,EAAI,YAAE8J,EAAW,eAAEC,EAAc,+BAACC,IACpE,MAAM,OAAE/I,GAAW4I,EAWnB,GAVA5I,EAAO9D,KAAOyH,EAAUG,QAAQ,eAAiBH,EAAUI,yBAAyB6E,EAAS7J,QAC7F4E,EAAU9F,QAAU+K,EAChBC,GACFxM,OAAOuJ,OAAO5F,EArBtB,SAAqB2D,GACnB,MAAMqF,EAAQrF,EAAUG,QAAQ,KAChC,OAAKkF,EAIE,CAAEA,QAAOvG,YADIkB,EAAUG,QAAQ,eAAiBH,EAAUI,MAAM,6BAF9D,GAkBmBtB,CAAYkB,IAMpC3D,EAAOoE,KAAOT,EAAUG,QAAQ,MAC5B9D,EAAOoE,OAA0C,IAAjC2E,EAEhB,OADA/I,EAAOwH,YAAc7D,EAAUG,QAAQ,MAAQH,EAAUI,iCAAiChF,KACnF6J,EAOX,IALI5I,EAAOoE,MAAST,EAAUI,kBAAkBhF,KAIhD6J,EAASK,QAAU,KACN,CAEX,GADAjJ,EAAO2E,MAAQhB,EAAUG,QAAQ,KAC7B9D,EAAO2E,MAET,OADA3E,EAAOwH,YAAc7D,EAAUG,QAAQ,MAAQH,EAAUI,iCAAiChF,KACnF6J,EAET,MAAMM,EAAK,EAAmBrC,MAAMlD,GACpC,IAAIwF,EACJ,IAAK,MAAO5C,KAAW6C,KAASN,EAE9B,GADAK,EAAM5C,EAAO5C,KAAcyF,GAEzB,MAGCD,GACHxF,EAAUI,MAAM,kBAElBoF,EAAIjE,SAAWgE,EACfN,EAASK,QAAQvH,KAAKyH,IAI1B,cACE,QAAS5N,KAAKyE,OAAOJ,QAEvB,WACE,OAAO,EAASrE,KAAKyE,OAAO9D,KAAKU,OAEnC,kBACE,OAAKrB,KAAKyE,OAAOyC,YAGV,EAASlH,KAAKyE,OAAOyC,YAAY7F,OAF/B,KAKX,UAAUqG,GACR,IAAK,MAAMoG,KAAU9N,KAAK0N,QACpBI,EAAO1D,iBACF0D,EAAO1D,SAAS1C,KC9E1B,MAAM,UAAiBZ,EAI5B,aAAasB,GACX,MAAM3D,EAAS,GAEf,GADAA,EAAOmE,KAAOR,EAAUG,QAAQ,UAC3B9D,EAAOmE,KACV,OAEF,IAAInB,EAAU6B,EAAelB,GAC7B,IAAKX,EAAS,CACZ,MAAMmB,EAAOR,EAAUG,QAAQ,eAAiBH,EAAUI,MAAM,sBAChEf,EAAU,IAAI,EAAK,CAAErF,OAAQgG,EAAUhG,OAAQqC,OAAQ,CAAEmE,UAEvDR,EAAUxB,MAAM,MAClBwB,EAAUI,MAAM,qCAElBf,EAAQjE,KAAO,aACfiB,EAAO9D,KAAOyH,EAAUG,QAAQ,eAAiBH,EAAUI,MAAM,sBACjE/D,EAAO4F,OAASjC,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,gCAC1D/D,EAAOpD,MAAQiJ,EAAYlC,IAAcA,EAAUI,MAAM,uBACzD/D,EAAOwH,YAAc7D,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,oCAC/D,MAAMG,EAAM,IAAI,EAAS,CAAEvG,OAAQgG,EAAUhG,OAAQqC,WAErD,OADAkE,EAAIlB,QAAUA,EACPkB,EAGT,WACE,MAAO,QAET,WACE,OAAOoF,SAAS/N,KAAKyE,OAAO9D,KAAKU,OAEnC,YACE,OAAOmJ,EAAWxK,KAAKyE,OAAOpD,QCpC3B,MAAM,UAAqByF,EAIhC,aAAasB,GACX,MAAMsD,EAAiBtD,EAAU/F,SAC3BoC,EAAS,GACTkE,EAAM,IAAI,EAAa,CAAEvG,OAAQgG,EAAUhG,OAAQqC,WASzD,GARAA,EAAO2H,SAAWhE,EAAUG,QAAQ,YAC/B9D,EAAO2H,WACV3H,EAAOuJ,MAAQ5F,EAAUG,QAAQ,UAEnC9D,EAAOmE,KACLnE,EAAO2H,SAAWhE,EAAUG,QAAQ,UAAW,WAC/C9D,EAAOuJ,MAAQ5F,EAAUG,QAAQ,YACjCH,EAAUG,QAAQ,WAAY,UAAW,YACtC9D,EAAOmE,KAEV,YADAR,EAAU0D,UAAUJ,GAItB,MAAM,KAAElI,GAASmF,EACXsF,EAA8B,YAATzK,GAAsBmF,EAAIqF,MAC/CE,EAAoBD,GAA+B,aAATzK,EAEhDiB,EAAOoE,KAAOT,EAAUG,QAAQ,MAAQH,EAAUI,yCAAyChF,iBAC3F,MAAM+I,EAAQxD,EAA8BX,IAAcA,EAAUI,oCAAoChF,iBAcxG,OAbAmF,EAAIlB,QAAU,CAAC8E,GACX2B,IACF3B,EAAM9H,OAAOyE,UAAYd,EAAUG,QAAQ,KACvCgE,EAAM9H,OAAOyE,UACfP,EAAIlB,QAAQtB,KAAK4C,EAA8BX,IAExC6F,GACP7F,EAAUI,yCAAyChF,kBAGvDiB,EAAO2E,MAAQhB,EAAUG,QAAQ,MAAQH,EAAUI,4CAA4ChF,iBAC/FiB,EAAOwH,YAAc7D,EAAUG,QAAQ,MAAQH,EAAUI,iCAAiChF,iBAEnFmF,EAGT,WACE,OAAO3I,KAAKyE,OAAOmE,KAAKvH,MAE1B,eACE,QAASrB,KAAKyE,OAAO2H,SAEvB,YACE,QAASpM,KAAKyE,OAAOuJ,OCzCzB,SAASG,EAAc/F,GACrB,MAAM2D,EAAU3D,EAAUG,QAAQ,UAClC,GAAKwD,EAIL,OAHe,EAAUT,MAAMlD,EAAW,CAAE2D,aAC1C,EAAUT,MAAMlD,EAAW,CAAE2D,aAC7B3D,EAAUI,MAAM,4BAIb,MAAM,UAAkB,EAM7B,aAAaJ,EAAWQ,GAAM,QAAEvE,EAAU,KAAK,+BAACmJ,GAAkC,IAEhFY,QAAQC,IAAI,cAAcb,GAE1B,MAAM/I,EAAS,CAAEJ,UAASuE,QAC1B,OAAO,EAAU0C,MAAMlD,EAAW,IAAI,EAAU,CAAEhG,OAAQgG,EAAUhG,OAAQqC,WAAW,CACrFjB,KAAM,YACN8J,aAAcjJ,EACdkJ,eAAgB,CACd,CAAC,EAASjC,OACV,CAAC6C,GACD,CAACrB,GACD,CAAC,EAAaxB,OACd,CAAC,EAAUA,OACX,CAAC,EAAUA,QAGbkC,mCAIJ,WACE,MAAO,YAGT,UAAU9F,GAER,SADO1H,KAAK2J,SAASS,SAAS1C,IAE3B1H,KAAKqE,SACNrE,KAAK2J,SAAS2E,MAAM7C,GAA4B,YAAjBA,EAAQ9K,OACvCX,KAAK2J,SAAS2E,MAAM7C,GAA4B,sBAAjBA,EAAQ9K,MACvC,CACA,MAAM4B,EAAU,oTAKVmC,EAAgB1E,KAAKoC,OAAQpC,KAAKyE,OAAO9D,KAAMX,KAAMuC,EAAS,CAClEG,QAASqK,EAAwB/M,cAI9B6G,MAAMuD,SAAS1C,GACjB1H,KAAKqE,gBCpEP,UAA0CqD,EAAMtH,GACrD,MAAMmO,EAAU,IAAIC,IAAIC,EAAcrO,GAAGgD,IAAIsL,GAAMA,EAAG/N,OAChDgO,EAAWjH,EAAKiH,SAAS1N,IAAIb,EAAEO,OAAS,GACxCiO,EAASlH,EAAKmH,SAAS5N,IAAIb,EAAEO,OAAS,GAC5C,IAAK,MAAMmO,IAAO,IAAIH,KAAaC,GAAS,CAC1C,MAAMG,EAAYN,EAAcK,SACzBE,EAAiBD,EAAWR,EAASO,EAAK1O,GACjD,IAAK,MAAM6O,KAAYF,EACrBR,EAAQW,IAAID,EAAStO,MAIzB,SAAUqO,EAAiBD,EAAWI,EAAWL,EAAKlG,GACpD,IAAK,MAAMqG,KAAYF,EAAW,CAChC,MAAM,KAAEpO,GAASsO,EACjB,GAAItO,GAAQwO,EAAUnH,IAAIrH,GAAO,CAC/B,MAAM4B,oBAA4B5B,uDAA0DiI,EAAKjI,6CAC3F+D,EAAgBoK,EAAI1M,OAAQ6M,EAASxK,OAAO9D,KAAMmO,EAAKvM,KAKnE,SAASkM,EAAcrO,GACrB,OAAOA,EAAEsN,QACN3D,OAAO,EAAEvG,UAAmB,cAATA,ID6Cb4L,CAAgC1H,EAAM1H,QEjE5C,MAAM,UAAc,EAIzB,aAAaoI,EAAWQ,GAAM,QAAEvE,GAAY,IAC1C,MAAMI,EAAS,CAAEJ,UAASuE,QAE1B,GADAnE,EAAO2I,MAAQhF,EAAUG,QAAQ,SAC5B9D,EAAO2I,MAGZ,OAAO,EAAU9B,MAAMlD,EAAW,IAAI,EAAM,CAAEhG,OAAQgG,EAAUhG,OAAQqC,WAAW,CACjFjB,KAAM,kBACN+J,eAAgB,CACd,CAAC,EAASjC,OACV,CAACwB,GACD,CAAC,EAAUxB,MAAO,CAAEa,WAAW,IAC/B,CAAC,EAAUb,MAAO,CAAEU,SAAS,OAKnC,WACE,MAAO,mBCvBJ,MAAM,UAAclF,EAIzB,aAAasB,GACX,MAAM3D,EAAS,GACTkE,EAAM,IAAI,EAAM,CAAEvG,OAAQgG,EAAUhG,OAAQqC,WAQlD,OAPAkE,EAAIgB,SAAW,EAAmB2B,MAAMlD,GACxC3D,EAAO4K,SAAWjH,EAAUG,QAAQ,YACpCI,EAAIlB,QAAUsB,EAA8BX,EAAW,oBAAsBA,EAAUI,MAAM,kCAC7F/D,EAAO9D,KAAOyH,EAAUG,QAAQ,eAAiBH,EAAUI,MAAM,kCACjEG,EAAIkD,QAAU,EAAQP,MAAMlD,GACxB3D,EAAO4K,UAAY1G,EAAIkD,SAASzD,EAAUI,MAAM,2CACpD/D,EAAOwH,YAAc7D,EAAUG,QAAQ,MAAQH,EAAUI,MAAM,gDACxDG,EAGT,WACE,MAAO,QAET,WACE,OAAO,EAAS3I,KAAKyE,OAAO9D,KAAKU,OAEnC,eACE,QAASrB,KAAKyE,OAAO4K,SAGvB,UAAU3H,SACD1H,KAAKyH,QAAQ2C,SAAS1C,IC9B1B,MAAM,UAAmB,EAI9B,aAAaU,GAAW,QAAE/D,GAAY,IACpC,MAAMI,EAAS,CAAEJ,WAEjB,GADAI,EAAOmE,KAAOR,EAAUG,QAAQ,cAC3B9D,EAAOmE,KAGZ,OAAO,EAAU0C,MAAMlD,EAAW,IAAI,EAAW,CAAEhG,OAAQgG,EAAUhG,OAAQqC,WAAW,CACtFjB,KAAM,aACN8J,aAAcjJ,EACdkJ,eAAgB,CACd,CAAC,EAAMjC,UAKb,WACE,MAAO,cCXJ,MAAM,UAAkB,EAI7B,aAAalD,GAAW,QAAE/D,EAAO,iCAACiL,GAAqC,IAErElB,QAAQC,IAAI,cAAciB,GAG1B,MAAM7K,EAAS,CAAEJ,WAEjB,GADAI,EAAOmE,KAAOR,EAAUG,QAAQ,cAC3B9D,EAAOmE,KACV,OAGF,IAAI2E,EAeJ,OAbIA,GADoC,IAArC+B,EACkB,CACf,CAAC,EAAShE,OAEV,CAAC,EAAUA,MAAO,CAAEa,WAAW,EAAMC,UAAU,IAC/C,CAAC,EAAUd,MAAO,CAAEU,SAAS,KAGd,CACf,CAAC,EAAUV,MAAO,CAAEa,WAAW,EAAMC,UAAU,IAC/C,CAAC,EAAUd,MAAO,CAAEU,SAAS,KAI5B,EAAUV,MAAMlD,EAAW,IAAI,EAAU,CAAEhG,OAAQgG,EAAUhG,OAAQqC,WAAW,CACrFjB,KAAM,YACN+J,eAAgBA,IAKpB,WACE,MAAO,YAGT,UAAU7F,GACR,IAAK1H,KAAKqE,SAAWrE,KAAK2J,SAAS2E,MAAM7C,GAA4B,YAAjBA,EAAQ9K,MAAqB,CAC/E,MAAM4B,EAAU,gTAKVmC,EAAgB1E,KAAKoC,OAAQpC,KAAKyE,OAAO9D,KAAMX,KAAMuC,EAAS,CAClEG,QAASqK,EAAwB/M,cAG9B6G,MAAMuD,SAAS1C,IC3DnB,MAAM,UAA0B,EAIrC,aAAaU,EAAWmH,GAAU,QAAElL,EAAU,MAAS,IACrD,MAAMI,EAAS,CAAE8K,YAEjB,GADA9K,EAAOmE,KAAOR,EAAUG,QAAQ,aAC3B9D,EAAOmE,KAGZ,OAAO,EAAU0C,MAAMlD,EAAW,IAAI,EAAkB,CAAEhG,OAAQgG,EAAUhG,OAAQqC,WAAW,CAC7FjB,KAAM,qBACN8J,aAAcjJ,EACdkJ,eAAgB,CACd,CAAC,EAASjC,OACV,CAAC,EAAUA,MAAO,CAAEU,SAAS,OAKnC,WACE,MAAO,sBCPX,SAASwD,EAAcpH,EAAWxD,GAChC,MAAMxC,EAASgG,EAAUhG,OAEzB,SAASoG,EAAMnD,GACb+C,EAAUI,MAAMnD,GAGlB,SAASkD,KAAW5B,GAClB,OAAOyB,EAAUG,WAAW5B,GAY9B,SAAS8I,EAAWC,GAIlB,MAAM9G,EAAOL,EAAQ,aACrB,GAAKK,EAIL,OAHY,EAAM0C,MAAMlD,EAAWQ,EAAM8G,IACvC,EAAUpE,MAAMlD,EAAWQ,EAAM8G,IACjClH,EAAM,gCAcV,SAASmH,EAAW/K,GAElB,OAjCF,WACE,MAAM2K,EAAWhH,EAAQ,YACzB,GAAKgH,EACL,OAAInH,EAAUxB,MAAM,aACX,EAAkB0E,MAAMlD,EAAWmH,GAErC,EAAiBjE,MAAMlD,EAAWmH,GA2BlCA,IAELE,EAAW7K,IAdf,WACE,MAAMP,EAAUkE,EAAQ,WACxB,GAAKlE,EACL,OAAO,EAAWiH,MAAMlD,EAAW,CAAE/D,aACnCoL,EAAW,CAAEpL,aACb,EAAUiH,MAAMlD,EAAW,CAAE/D,aAC7BmE,EAAM,qCASNnE,IACA,EAAWiH,MAAMlD,IACjB,EAAKkD,MAAMlD,IACX,EAAQkD,MAAMlD,IACd,EAASkD,MAAMlD,IACf,EAAUkD,MAAMlD,EAAUxD,GAyB9B,MAAMgL,EArBN,SAAqBhL,GAEnB,IAAKxC,EAAOqB,OAAQ,MAAO,GAC3B,MAAMiE,EAAO,GACb,OAAa,CACX,MAAMiG,EAAK,EAAmBrC,MAAMlD,GAC9BR,EAAM+H,EAAW/K,GAEvB,IAAKgD,EAAK,CACJ+F,EAAGlK,QAAQ+E,EAAM,6BACrB,MAEFZ,EAAI+B,SAAWgE,EACfjG,EAAKvB,KAAKyB,GAEZ,MAAMiI,EAAMtH,EAAQ,OAIpB,OAHI3D,EAAQkL,UACVpI,EAAKvB,KAAK0J,GAELnI,EAEGqI,CAAYnL,GAGxB,OADIwD,EAAU/F,SAAWD,EAAOqB,QAAQ+E,EAAM,uBACvCoH,EAGF,SAAStE,EAAMjG,EAAKT,EAAU,IAInC,MAAMwD,EAAY,IAAI,EAAU/C,GAIhC,YAHkC,IAAvBT,EAAQL,aACjB6D,EAAUhG,OAAOzB,KAAOiE,EAAQL,YAE3BiL,EAAcpH,EAAWxD,GC5GlC,SAASoL,EAAKzE,GACZ,OAAOA,EAGT,MAAM0E,GAAY,CAChBC,KAAM1D,GAASA,EAAMlJ,KAAK,IAC1BD,OAAQ2M,EACRrP,KAAMqP,EACN9F,UAAW8F,EACXxM,KAAMwM,EACNzG,QAASyG,EACT9I,YAAa8I,EACbL,WAAYK,EACZG,kBAAmBH,EACnBI,2BAA4BJ,GAGvB,SAASK,GAAMC,GAAOL,UAAWM,EAAKN,IAAc,IAGzD,SAAS/F,EAAUsG,GAAK,UAAEC,EAAS,QAAErM,IAInC,OAHKqM,IACHA,EAAYD,EAAItK,WAAW,KAAOsK,EAAI3N,MAAM,GAAK2N,GAE5CD,EAAGrG,UAAUsG,EAAKC,EAAWrM,GAGtC,SAASO,EAAMrD,EAAGoP,EAAUV,KAASnC,GACnC,IAAKvM,EACH,MAAO,GAET,MAAMD,EAAQqP,EAAQpP,EAAED,SAAUwM,GAClC,OAAO0C,EAAGL,KAAK,CAACK,EAAGlN,OAAO/B,EAAE+B,QAAShC,IAGvC,SAASsP,EAAgBrP,EAAG8C,GAC1B,OAAOO,EAAMrD,EAAG4I,EAAW,CAAE9F,YAG/B,SAASwM,EAAWtP,EAAGiK,GACrB,OAAO5G,EAAMrD,EAAGiP,EAAG5P,KAAM4K,GAG3B,SAASsF,EAAUC,GACjB,GAAIA,EAAGnJ,OAASmJ,EAAGvH,QACjB,OAAOgH,EAAGL,KAAK,CACbvL,EAAMmM,EAAGrM,OAAOmE,KAAM2H,EAAGhH,SACzB5E,EAAMmM,EAAGrM,OAAOoE,SACbiI,EAAG5I,QAAQ9E,IAAII,GAClBmB,EAAMmM,EAAGrM,OAAO2E,SAGpB,MAAM2H,EAAaD,EAAGrM,OAAOoF,QAAUiH,EAAGrM,OAAOmE,KAC3CiB,EAASiH,EAAGrM,OAAOoF,OAAS,CAChCiH,EAAGrM,OAAOoF,OAAOxI,MACjBkP,EAAGlN,OAAOyN,EAAGrM,OAAOmE,KAAKvF,SACvB,GACE2N,EAAM9G,EAAUqG,EAAGL,KAAK,IACzBrG,EACHiH,EAAGrM,OAAOmE,KAAKvH,MACfsD,EAAMmM,EAAGrM,OAAOqF,WACd,CAAE2G,UAAWK,EAAGrJ,QAASrD,QAAS0M,IACtC,OAAOP,EAAGL,KAAK,CAACK,EAAGlN,OAAO0N,EAAW1N,QAAS2N,IAEhD,SAASxN,EAAKsN,GACZ,OAAOP,EAAGL,KAAK,CACbe,EAAoBH,EAAGnH,UACvBkH,EAAUC,GACVnM,EAAMmM,EAAGrM,OAAO6D,UAChB3D,EAAMmM,EAAGrM,OAAOyE,aAGpB,SAASgI,EAAStJ,GAChB,OAAKA,EAGE2I,EAAGL,KAAK,CACbvL,EAAMiD,EAAInD,OAAO4F,WACdzC,EAAI2C,WAAWnH,IAAI9B,GAAKqD,EAAMrD,MAJ1B,GAOX,SAAS4K,EAASX,GAChB,OAAOgF,EAAGL,KAAK,CACbe,EAAoB1F,EAAI5B,UACxBhF,EAAM4G,EAAI9G,OAAOkH,UACjB4E,EAAG/M,KAAKA,EAAK+H,EAAI9D,UACjB9C,EAAM4G,EAAI9G,OAAOmH,UACjBgF,EAAWrF,EAAI9G,OAAO9D,KAAM,CAAEwQ,KAAM5F,IACpC2F,EAAS3F,EAAIM,SACblH,EAAM4G,EAAI9G,OAAOyE,aASrB,SAASkI,EAAYN,GACnB,MAAM,QAAEhG,GAAYgG,EAAGzF,OACvB,OAAOkF,EAAGL,KAAK,CACbK,EAAGlN,OAAOyN,EAAGrM,OAAO9D,KAAK0C,QACzBkN,EAAGJ,kBAAkBI,EAAGL,KAAK,CAC3BK,EAAGH,2BAA2BU,EAAGnQ,MACjCgE,EAAMmM,EAAGzF,OAAO5G,OAAO4F,QACvBsG,EAAgBG,EAAGzF,OAAO5G,OAAOmG,cAAekG,GAChDnM,EAAMmM,EAAGzF,OAAO5G,OAAOoE,SACnBiI,EAAGzF,OAAOR,KACZiG,EAAGzF,OAAOR,KAAKzH,IACD,oBAAZ0H,EAAgCuG,IAjB1C,SAAoBA,EAAIjN,GACtB,OAAOmM,EAAGL,KAAK,CACbS,EAAgBU,EAAG5M,OAAOpD,MAAO+C,GACjCO,EAAM0M,EAAG5M,OAAOyE,cAc4BmD,CAAWgF,EAAIP,GAAM5E,GAF1C,GAIrBvH,EAAMmM,EAAGzF,OAAO5G,OAAO2E,UAEzBzE,EAAMmM,EAAGrM,OAAOyE,aAGpB,SAAS+H,EAAoBK,GAC3B,OAAKA,EAAK7N,OACH8M,EAAGL,KAAK,CACbvL,EAAM2M,EAAK7M,OAAOoE,SACfyI,EAAKlO,IAAIgO,GACZzM,EAAM2M,EAAK7M,OAAO2E,SAJK,GA+C3B,SAASmI,EAAUT,GACjB,OAAOP,EAAGZ,WAAWY,EAAGL,KAAK,CAC3Be,EAAoBH,EAAGnH,UACvBhF,EAAMmM,EAAGrM,OAAO8K,UAChB5K,EAAMmM,EAAGrM,OAAOJ,SAChBM,EAAMmM,EAAGrM,OAAOmE,MAChBjE,EAAMmM,EAAGrM,OAAO2I,OAChBwD,EAAWE,EAAGrM,OAAO9D,KAAM,CAAEwQ,KAAML,KAlBlBU,EAmBLV,EAlBTU,EAAI/M,OAAOyC,YAGTqJ,EAAGL,KAAK,CACbvL,EAAM6M,EAAI/M,OAAOgJ,OACjB8C,EAAGlN,OAAOmO,EAAI/M,OAAOyC,YAAY7D,QACjCkN,EAAGrJ,YAAYgD,EAAUsH,EAAI/M,OAAOyC,YAAY7F,MAAO,CAAE+C,QAASoN,OAL3D,IAkBP7M,EAAMmM,EAAGrM,OAAOoE,MAChB4I,EAAQX,EAAGpD,QAASoD,GACpBnM,EAAMmM,EAAGrM,OAAO2E,OAChBzE,EAAMmM,EAAGrM,OAAOwH,eACd,CAAEkF,KAAML,IAxBd,IAAqBU,EAoGrB,SAASE,EAAcZ,EAAIa,GACzB,OAAOpB,EAAGZ,WAAWY,EAAGL,KAAK,CAC3Be,EAAoBH,EAAGnH,UACvBhF,EAAMmM,EAAGrM,OAAO2H,UAChBzH,EAAMmM,EAAGrM,OAAOuJ,OAChBrJ,EAAMmM,EAAGrM,OAAOmE,KAAM2H,EAAGhH,SACzB5E,EAAMmM,EAAGrM,OAAOoE,MAChB0H,EAAGL,KAAKY,EAAGrJ,QAAQrE,IAAII,IACvBmB,EAAMmM,EAAGrM,OAAO2E,OAChBzE,EAAMmM,EAAGrM,OAAOwH,eACd,CAAEkF,KAAML,EAAIa,WArPlBpB,EAAKzP,OAAOuJ,OAAO,GAAI4F,GAAWM,GA2PlC,MAAMqB,EAAQ,CACZC,UAAWN,EACX,kBAAmBA,EACnBO,UAAWP,EACXQ,UApJF,SAAmBjB,EAAIa,GACrB,MAAMK,EAAOlB,EAAGrJ,QAAU,CACxB8I,EAAG/M,KAAKA,EAAKsN,EAAGrJ,UAChBmJ,EAAWE,EAAGrM,OAAO9D,KAAM,CAAEwQ,KAAML,EAAIa,WACvChN,EAAMmM,EAAGrM,OAAOoE,MAChB0H,EAAGL,KAAKY,EAAGtF,UAAUpI,IAAI8I,IACzBvH,EAAMmM,EAAGrM,OAAO2E,QACd,GACJ,OAAOmH,EAAGZ,WAAWY,EAAGL,KAAK,CAC3Be,EAAoBH,EAAGnH,UACvBhF,EAAMmM,EAAGrM,OAAOsH,YACbiG,EACHrN,EAAMmM,EAAGrM,OAAOwH,eACd,CAAEkF,KAAML,EAAIa,YAwIhBM,UArIF,SAAmBnB,EAAIa,GACrB,OAAOpB,EAAGZ,WAAWY,EAAGL,KAAK,CAC3Be,EAAoBH,EAAGnH,UACvBhF,EAAMmM,EAAGrM,OAAOsH,SAChBpH,EAAMmM,EAAGrM,OAAO2H,UAChBzH,EAAMmM,EAAGrM,OAAOmE,MAChB2H,EAAG/M,KAAKA,EAAKsN,EAAGrJ,UAChBmJ,EAAWE,EAAGrM,OAAO9D,KAAM,CAAEwQ,KAAML,EAAIa,WACvChN,EAAMmM,EAAGrM,OAAOwH,eACd,CAAEkF,KAAML,EAAIa,YA6HhBO,WAAYX,EACZY,MAhGF,SAAerB,EAAIa,GACjB,OAAOpB,EAAGZ,WAAWY,EAAGL,KAAK,CAC3Be,EAAoBH,EAAGnH,UACvBhF,EAAMmM,EAAGrM,OAAO4K,UAChBkB,EAAG/M,KAAKA,EAAKsN,EAAGrJ,UAChBmJ,EAAWE,EAAGrM,OAAO9D,KAAM,CAAEwQ,KAAML,EAAIa,WACvCT,EAASJ,EAAGjF,SACZlH,EAAMmM,EAAGrM,OAAOwH,eACd,CAAEkF,KAAML,EAAIa,YAyFhBS,MAvFF,SAAgBtB,EAAIa,GAClB,OAAOpB,EAAGZ,WAAWY,EAAGL,KAAK,CAC3Be,EAAoBH,EAAGnH,UACvBhF,EAAMmM,EAAGrM,OAAOmE,MAChB2H,EAAG/M,KAAKA,EAAKsN,EAAGrJ,UAChBmJ,EAAWE,EAAGrM,OAAO9D,KAAM,CAAEwQ,KAAML,EAAIa,WACvChN,EAAMmM,EAAGrM,OAAO4F,QAChB1F,EAAMmM,EAAGrM,OAAOpD,OAChBsD,EAAMmM,EAAGrM,OAAOwH,eACd,CAAEkF,KAAML,EAAIa,YA+EhB3H,QA7EF,SAAiB8G,GACf,OAAOP,EAAGZ,WAAWY,EAAGL,KAAK,CAC3Be,EAAoBH,EAAGnH,UACvBhF,EAAMmM,EAAGrM,OAAOmE,MAChB2H,EAAG/M,KAAKA,EAAKsN,EAAGrJ,UAChBmJ,EAAWE,EAAGrM,OAAO9D,KAAM,CAAEwQ,KAAML,IACnCnM,EAAMmM,EAAGrM,OAAOwH,eACd,CAAEkF,KAAML,KAuEZ9K,SArEF,SAAkB8K,GAChB,OAAOP,EAAGZ,WAAWY,EAAGL,KAAK,CAC3Be,EAAoBH,EAAGnH,UACvBgH,EAAgBG,EAAGrM,OAAOwF,OAAQ6G,GAClCnM,EAAMmM,EAAGrM,OAAOuB,UAChB2K,EAAgBG,EAAGrM,OAAO2I,MAAO0D,GACjCnM,EAAMmM,EAAGrM,OAAOwH,eACd,CAAEkF,KAAML,KA+DZvB,SA7DF,SAAkBuB,GAChB,OAAOP,EAAGZ,WAAWY,EAAGL,KAAK,CAC3Be,EAAoBH,EAAGnH,UACvBhF,EAAMmM,EAAGrM,OAAOmE,MAChBgI,EAAWE,EAAGrM,OAAO9D,KAAM,CAAEwQ,KAAML,IACnCnM,EAAMmM,EAAGrM,OAAO4F,QAChBkG,EAAG/M,KAAKA,EAAKsN,EAAGrJ,UAChB9C,EAAMmM,EAAGrM,OAAOoE,SACbiI,EAAGtF,UAAUpI,IAAI8I,GACpBvH,EAAMmM,EAAGrM,OAAO2E,OAChBzE,EAAMmM,EAAGrM,OAAOwH,eACd,CAAEkF,KAAML,KAmDZuB,KAjDF,SAAevB,GACb,OAAOP,EAAGZ,WAAWY,EAAGL,KAAK,CAC3Be,EAAoBH,EAAGnH,UACvBhF,EAAMmM,EAAGrM,OAAOmE,MAChBgI,EAAWE,EAAGrM,OAAO9D,KAAM,CAAEwQ,KAAML,IACnCnM,EAAMmM,EAAGrM,OAAOoE,MAChB4I,EAAQX,EAAG3D,OAAQ2D,GACnBnM,EAAMmM,EAAGrM,OAAO2E,OAChBzE,EAAMmM,EAAGrM,OAAOwH,eACd,CAAEkF,KAAML,KAyCZ,aAvCF,SAAoBwB,EAAGX,GACrB,OAAOpB,EAAGL,KAAK,CACbK,EAAGlN,OAAOiP,EAAE7N,OAAOpD,MAAMgC,QACzBkN,EAAGZ,WACDY,EAAGL,KAAK,CAAC,IAAKK,EAAG5P,KAAK2R,EAAEjR,MAAO,CAAE8P,KAAMmB,EAAGX,WAAW,MACrD,CAAER,KAAMmB,EAAGX,WAEbhN,EAAM2N,EAAE7N,OAAOyE,cAiCjBqJ,SAAUb,EACVc,eAAgBd,EAChBe,QAASf,EACTgB,QAAShB,EACT,qBAAsBH,EACtB1B,IAvBF,SAAaiB,GACX,OAAOP,EAAGlN,OAAOyN,EAAGzN,UA+BtB,SAASoO,EAAQkB,EAAQhB,GACvB,IAAKgB,EAAQ,OACb,MAAMC,EAAUD,EAAOvP,IAAIyP,IAT7B,SAAkB/B,EAAIa,GAEpB,IADmBC,EAAMd,EAAGtN,MAE1B,MAAM,IAAI4C,eAAe0K,EAAGtN,wBAE9B,OAAOoO,EAAMd,EAAGtN,MAAMsN,EAAIa,IAIUmB,CAASD,EAAOlB,IACpD,OAAOpB,EAAGL,KAAK0C,GAEjB,OAAOnB,EAAQnB,GC5SjB,SAASyC,GAAYC,EAAKnL,GACxB,MAAMzE,EAAM,IAAI6P,IACVjN,EAAWgN,EAAIjJ,OAAOnC,GAAoB,aAAbA,EAAIpE,MACvC,IAAK,MAAM0P,KAAWlN,EAAU,CAC9B,MAAMoH,EAAQvF,EAAO5G,IAAIiS,EAAQlN,UACjC,IAAKoH,EACH,SAEF,MAAM+F,EAAQ/P,EAAInC,IAAIiS,EAAQjJ,QAC1BkJ,EACFA,EAAMhN,KAAKiH,GAEXhK,EAAI6E,IAAIiL,EAAQjJ,OAAQ,CAACmD,IAG7B,OAAOhK,EA8CT,SAAUgQ,GAAiB9C,GACzB,MAAM5I,EA5CR,SAA0BsL,GACxB,MAAMnL,EAAS,IAAIoL,IACbI,EAAa,IAAI7E,IACjBG,EAAW,IAAIsE,IACrB,IAAK,MAAMrL,KAAOoL,EAChB,GAAIpL,EAAIvD,QAAR,CACE,MAAM8O,EAAQxE,EAAS1N,IAAI2G,EAAIjH,MAC3BwS,EACFA,EAAMhN,KAAKyB,GAEX+G,EAAS1G,IAAIL,EAAIjH,KAAM,CAACiH,SAIvBA,EAAIjH,OAGJkH,EAAOG,IAAIJ,EAAIjH,MAGlB0S,EAAWnE,IAAItH,GAFfC,EAAOI,IAAIL,EAAIjH,KAAMiH,IAKzB,MAAO,CACLoL,MACAnL,SACA8G,WACA0E,aACAxE,SAAUkE,GAAYC,EAAKnL,GAC3BE,MAAO,CACLD,0BAA2B,IAAIwL,UActBC,CAAiBjD,GAC9B,IAAK,MAAM1I,KAAOF,EAAKsL,IACjBpL,EAAIwC,iBACCxC,EAAIwC,SAAS1C,UAZ1B,WAA+B,OAAEG,EAAM,WAAEwL,IACvC,IAAK,MAAMG,KAAOH,EAAY,CAC5B,MAAM,KAAE1S,GAAS6S,EACXjR,eAAuB5B,eAAkBkH,EAAO5G,IAAIN,GAAM6C,+BAC1D,EAAMgQ,EAAIpR,OAAQoR,EAAI/O,OAAO9D,KAAM6S,EAAKjR,IAWzCkR,CAAqB/L,GAcvB,SAAS0C,GAASkG,GACvB,MAAO,IAAI8C,IAXID,EAWqB7C,EAVhC6C,EAAMO,KACDP,EAAMO,OAER,GAAGxO,UAAUiO,MAJtB,IAAiBA,EC5EjB","file":"webidl2-mozilla-compatible.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"WebIDL2\"] = factory();\n\telse\n\t\troot[\"WebIDL2\"] = factory();\n})(this, function() {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 0);\n","/**\n * @param {string} text\n */\nfunction lastLine(text) {\n  const splitted = text.split(\"\\n\");\n  return splitted[splitted.length - 1];\n}\n\n/**\n * @typedef {object} WebIDL2ErrorOptions\n * @property {\"error\" | \"warning\"} level\n * @property {Function} autofix\n *\n * @param {string} message error message\n * @param {\"Syntax\" | \"Validation\"} kind error type\n * @param {WebIDL2ErrorOptions} [options]\n */\nfunction error(source, position, current, message, kind, { level = \"error\", autofix } = {}) {\n  /**\n   * @param {number} count\n   */\n  function sliceTokens(count) {\n    return count > 0 ?\n      source.slice(position, position + count) :\n      source.slice(Math.max(position + count, 0), position);\n  }\n\n  function tokensToText(inputs, { precedes } = {}) {\n    const text = inputs.map(t => t.trivia + t.value).join(\"\");\n    const nextToken = source[position];\n    if (nextToken.type === \"eof\") {\n      return text;\n    }\n    if (precedes) {\n      return text + nextToken.trivia;\n    }\n    return text.slice(nextToken.trivia.length);\n  }\n\n  const maxTokens = 5; // arbitrary but works well enough\n  const line =\n    source[position].type !== \"eof\" ? source[position].line :\n    source.length > 1 ? source[position - 1].line :\n    1;\n\n  const precedingLastLine = lastLine(\n    tokensToText(sliceTokens(-maxTokens), { precedes: true })\n  );\n\n  const subsequentTokens = sliceTokens(maxTokens);\n  const subsequentText = tokensToText(subsequentTokens);\n  const subsequentFirstLine = subsequentText.split(\"\\n\")[0];\n\n  const spaced = \" \".repeat(precedingLastLine.length) + \"^\";\n  const sourceContext = precedingLastLine + subsequentFirstLine + \"\\n\" + spaced;\n\n  const contextType = kind === \"Syntax\" ? \"since\" : \"inside\";\n  const inSourceName = source.name ? ` in ${source.name}` : \"\";\n  const grammaticalContext = (current && current.name) ? `, ${contextType} \\`${current.partial ? \"partial \" : \"\"}${current.type} ${current.name}\\`` : \"\";\n  const context = `${kind} error at line ${line}${inSourceName}${grammaticalContext}:\\n${sourceContext}`;\n  return {\n    message: `${context} ${message}`,\n    bareMessage: message,\n    context,\n    line,\n    sourceName: source.name,\n    level,\n    autofix,\n    input: subsequentText,\n    tokens: subsequentTokens\n  };\n}\n\n/**\n * @param {string} message error message\n */\nexport function syntaxError(source, position, current, message) {\n  return error(source, position, current, message, \"Syntax\");\n}\n\n/**\n * @param {string} message error message\n * @param {WebIDL2ErrorOptions} [options]\n */\nexport function validationError(source, token, current, message, options) {\n  return error(source, token.index, current, message, \"Validation\", options);\n}\n","import { syntaxError } from \"./error.js\";\n\n// These regular expressions use the sticky flag so they will only match at\n// the current location (ie. the offset of lastIndex).\nconst tokenRe = {\n  // This expression uses a lookahead assertion to catch false matches\n  // against integers early.\n  \"decimal\": /-?(?=[0-9]*\\.|[0-9]+[eE])(([0-9]+\\.[0-9]*|[0-9]*\\.[0-9]+)([Ee][-+]?[0-9]+)?|[0-9]+[Ee][-+]?[0-9]+)/y,\n  \"integer\": /-?(0([Xx][0-9A-Fa-f]+|[0-7]*)|[1-9][0-9]*)/y,\n  \"identifier\": /[_-]?[A-Za-z][0-9A-Z_a-z-]*/y,\n  \"string\": /\"[^\"]*\"/y,\n  \"whitespace\": /[\\t\\n\\r ]+/y,\n  \"comment\": /((\\/(\\/.*|\\*([^*]|\\*[^/])*\\*\\/)[\\t\\n\\r ]*)+)/y,\n  \"other\": /[^\\t\\n\\r 0-9A-Za-z]/y\n};\n\nexport const stringTypes = [\n  \"ByteString\",\n  \"DOMString\",\n  \"USVString\"\n];\n\nexport const argumentNameKeywords = [\n  \"async\",\n  \"attribute\",\n  \"callback\",\n  \"const\",\n  \"deleter\",\n  \"dictionary\",\n  \"enum\",\n  \"getter\",\n  \"includes\",\n  \"inherit\",\n  \"interface\",\n  \"iterable\",\n  \"maplike\",\n  \"namespace\",\n  \"partial\",\n  \"required\",\n  \"setlike\",\n  \"setter\",\n  \"static\",\n  \"stringifier\",\n  \"typedef\",\n  \"unrestricted\"\n];\n\nconst nonRegexTerminals = [\n  \"-Infinity\",\n  \"FrozenArray\",\n  \"Infinity\",\n  \"NaN\",\n  \"Promise\",\n  \"async\",\n  \"boolean\",\n  \"byte\",\n  \"double\",\n  \"false\",\n  \"float\",\n  \"long\",\n  \"mixin\",\n  \"null\",\n  \"octet\",\n  \"optional\",\n  \"or\",\n  \"readonly\",\n  \"record\",\n  \"sequence\",\n  \"short\",\n  \"true\",\n  \"unsigned\",\n  \"void\"\n].concat(argumentNameKeywords, stringTypes);\n\nconst punctuations = [\n  \"(\",\n  \")\",\n  \",\",\n  \"...\",\n  \":\",\n  \";\",\n  \"<\",\n  \"=\",\n  \">\",\n  \"?\",\n  \"[\",\n  \"]\",\n  \"{\",\n  \"}\"\n];\n\n/**\n * @param {string} str\n */\nfunction tokenise(str) {\n  const tokens = [];\n  let lastCharIndex = 0;\n  let trivia = \"\";\n  let line = 1;\n  let index = 0;\n  while (lastCharIndex < str.length) {\n    const nextChar = str.charAt(lastCharIndex);\n    let result = -1;\n\n    if (/[\\t\\n\\r ]/.test(nextChar)) {\n      result = attemptTokenMatch(\"whitespace\", { noFlushTrivia: true });\n    } else if (nextChar === '/') {\n      result = attemptTokenMatch(\"comment\", { noFlushTrivia: true });\n    }\n\n    if (result !== -1) {\n      const currentTrivia = tokens.pop().value;\n      line += (currentTrivia.match(/\\n/g) || []).length;\n      trivia += currentTrivia;\n      index -= 1;\n    } else if (/[-0-9.A-Z_a-z]/.test(nextChar)) {\n      result = attemptTokenMatch(\"decimal\");\n      if (result === -1) {\n        result = attemptTokenMatch(\"integer\");\n      }\n      if (result === -1) {\n        result = attemptTokenMatch(\"identifier\");\n        const token = tokens[tokens.length - 1];\n        if (result !== -1 && nonRegexTerminals.includes(token.value)) {\n          token.type = token.value;\n        }\n      }\n    } else if (nextChar === '\"') {\n      result = attemptTokenMatch(\"string\");\n    }\n\n    for (const punctuation of punctuations) {\n      if (str.startsWith(punctuation, lastCharIndex)) {\n        tokens.push({ type: punctuation, value: punctuation, trivia, line, index });\n        trivia = \"\";\n        lastCharIndex += punctuation.length;\n        result = lastCharIndex;\n        break;\n      }\n    }\n\n    // other as the last try\n    if (result === -1) {\n      result = attemptTokenMatch(\"other\");\n    }\n    if (result === -1) {\n      throw new Error(\"Token stream not progressing\");\n    }\n    lastCharIndex = result;\n    index += 1;\n  }\n\n  // remaining trivia as eof\n  tokens.push({\n    type: \"eof\",\n    value: \"\",\n    trivia\n  });\n\n  return tokens;\n\n  /**\n   * @param {keyof tokenRe} type\n   * @param {object} [options]\n   * @param {boolean} [options.noFlushTrivia]\n   */\n  function attemptTokenMatch(type, { noFlushTrivia } = {}) {\n    const re = tokenRe[type];\n    re.lastIndex = lastCharIndex;\n    const result = re.exec(str);\n    if (result) {\n      tokens.push({ type, value: result[0], trivia, line, index });\n      if (!noFlushTrivia) {\n        trivia = \"\";\n      }\n      return re.lastIndex;\n    }\n    return -1;\n  }\n}\n\nexport class Tokeniser {\n  /**\n   * @param {string} idl\n   */\n  constructor(idl) {\n    this.source = tokenise(idl);\n    this.position = 0;\n  }\n\n  /**\n   * @param {string} message\n   */\n  error(message) {\n    throw new WebIDLParseError(syntaxError(this.source, this.position, this.current, message));\n  }\n\n  /**\n   * @param {string} type\n   */\n  probe(type) {\n    return this.source.length > this.position && this.source[this.position].type === type;\n  }\n\n  /**\n   * @param  {...string} candidates\n   */\n  consume(...candidates) {\n    for (const type of candidates) {\n      if (!this.probe(type)) continue;\n      const token = this.source[this.position];\n      this.position++;\n      return token;\n    }\n  }\n\n  /**\n   * @param {number} position\n   */\n  unconsume(position) {\n    this.position = position;\n  }\n}\n\nclass WebIDLParseError extends Error {\n  constructor({ message, bareMessage, context, line, sourceName, input, tokens }) {\n    super(message);\n\n    this.name = \"WebIDLParseError\"; // not to be mangled\n    this.bareMessage = bareMessage;\n    this.context = context;\n    this.line = line;\n    this.sourceName = sourceName;\n    this.input = input;\n    this.tokens = tokens;\n  }\n}\n","export class Base {\n  constructor({ source, tokens }) {\n    Object.defineProperties(this, {\n      source: { value: source },\n      tokens: { value: tokens }\n    });\n  }\n\n  toJSON() {\n    const json = { type: undefined, name: undefined, inheritance: undefined };\n    let proto = this;\n    while (proto !== Object.prototype) {\n      const descMap = Object.getOwnPropertyDescriptors(proto);\n      for (const [key, value] of Object.entries(descMap)) {\n        if (value.enumerable || value.get) {\n          json[key] = this[key];\n        }\n      }\n      proto = Object.getPrototypeOf(proto);\n    }\n    return json;\n  }\n}\n","/**\n * Yields direct references to dictionary within union.\n */\nexport function* dictionaryWithinUnion(subtypes, defs) {\n  for (const subtype of subtypes) {\n    const def = defs.unique.get(subtype.idlType);\n    if (def && def.type === \"dictionary\") {\n      yield subtype;\n    }\n  }\n}\n\n/**\n * @return the type reference that ultimately includes dictionary.\n */\nexport function idlTypeIncludesDictionary(idlType, defs) {\n  if (!idlType.union) {\n    const def = defs.unique.get(idlType.idlType);\n    if (!def) {\n      return;\n    }\n    if (def.type === \"typedef\") {\n      const { typedefIncludesDictionary} = defs.cache;\n      if (typedefIncludesDictionary.has(def)) {\n        // Note that this also halts when it met indeterminate state\n        // to prevent infinite recursion\n        return typedefIncludesDictionary.get(def);\n      }\n      defs.cache.typedefIncludesDictionary.set(def, undefined); // indeterminate state\n      const result = idlTypeIncludesDictionary(def.idlType, defs);\n      defs.cache.typedefIncludesDictionary.set(def, result);\n      if (result) {\n        return idlType;\n      }\n    }\n    if (def.type === \"dictionary\") {\n      return idlType;\n    }\n  }\n  for (const subtype of idlType.subtype) {\n    const result = idlTypeIncludesDictionary(subtype, defs);\n    if (result) {\n      if (subtype.union) {\n        return result;\n      }\n      return subtype;\n    }\n  }\n}\n\n/**\n * @return true if the idlType directly references a typedef.\n */\nexport function referencesTypedef(idlType, defs) {\n  const result = defs.unique.get(idlType.idlType);\n  return result && result.type === \"typedef\";\n}\n","import { Base } from \"./base.js\";\nimport { unescape, type_with_extended_attributes, return_type, primitive_type } from \"./helpers.js\";\nimport { stringTypes } from \"../tokeniser.js\";\nimport { validationError } from \"../error.js\";\nimport { idlTypeIncludesDictionary } from \"../validators/helpers.js\";\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nfunction generic_type(tokeniser, typeName) {\n  const base = tokeniser.consume(\"FrozenArray\", \"Promise\", \"sequence\", \"record\");\n  if (!base) {\n    return;\n  }\n  const ret = new Type({ source: tokeniser.source, tokens: { base } });\n  ret.tokens.open = tokeniser.consume(\"<\") || tokeniser.error(`No opening bracket after ${base.type}`);\n  switch (base.type) {\n    case \"Promise\": {\n      if (tokeniser.probe(\"[\")) tokeniser.error(\"Promise type cannot have extended attribute\");\n      const subtype = return_type(tokeniser, typeName) || tokeniser.error(\"Missing Promise subtype\");\n      ret.subtype.push(subtype);\n      break;\n    }\n    case \"sequence\":\n    case \"FrozenArray\": {\n      const subtype = type_with_extended_attributes(tokeniser, typeName) || tokeniser.error(`Missing ${base.type} subtype`);\n      ret.subtype.push(subtype);\n      break;\n    }\n    case \"record\": {\n      if (tokeniser.probe(\"[\")) tokeniser.error(\"Record key cannot have extended attribute\");\n      const keyType = tokeniser.consume(...stringTypes) || tokeniser.error(`Record key must be one of: ${stringTypes.join(\", \")}`);\n      const keyIdlType = new Type({ source: tokeniser.source, tokens: { base: keyType }});\n      keyIdlType.tokens.separator = tokeniser.consume(\",\") || tokeniser.error(\"Missing comma after record key type\");\n      keyIdlType.type = typeName;\n      const valueType = type_with_extended_attributes(tokeniser, typeName) || tokeniser.error(\"Error parsing generic type record\");\n      ret.subtype.push(keyIdlType, valueType);\n      break;\n    }\n  }\n  if (!ret.idlType) tokeniser.error(`Error parsing generic type ${base.type}`);\n  ret.tokens.close = tokeniser.consume(\">\") || tokeniser.error(`Missing closing bracket after ${base.type}`);\n  return ret;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nfunction type_suffix(tokeniser, obj) {\n  const nullable = tokeniser.consume(\"?\");\n  if (nullable) {\n    obj.tokens.nullable = nullable;\n  }\n  if (tokeniser.probe(\"?\")) tokeniser.error(\"Can't nullable more than once\");\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nfunction single_type(tokeniser, typeName) {\n  let ret = generic_type(tokeniser, typeName) || primitive_type(tokeniser);\n  if (!ret) {\n    const base = tokeniser.consume(\"identifier\", ...stringTypes);\n    if (!base) {\n      return;\n    }\n    ret = new Type({ source: tokeniser.source, tokens: { base } });\n    if (tokeniser.probe(\"<\")) tokeniser.error(`Unsupported generic type ${base.value}`);\n  }\n  if (ret.generic === \"Promise\" && tokeniser.probe(\"?\")) {\n    tokeniser.error(\"Promise type cannot be nullable\");\n  }\n  ret.type = typeName || null;\n  type_suffix(tokeniser, ret);\n  if (ret.nullable && ret.idlType === \"any\") tokeniser.error(\"Type `any` cannot be made nullable\");\n  return ret;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} type\n */\nfunction union_type(tokeniser, type) {\n  const tokens = {};\n  tokens.open = tokeniser.consume(\"(\");\n  if (!tokens.open) return;\n  const ret = new Type({ source: tokeniser.source, tokens });\n  ret.type = type || null;\n  while (true) {\n    const typ = type_with_extended_attributes(tokeniser) || tokeniser.error(\"No type after open parenthesis or 'or' in union type\");\n    if (typ.idlType === \"any\") tokeniser.error(\"Type `any` cannot be included in a union type\");\n    ret.subtype.push(typ);\n    const or = tokeniser.consume(\"or\");\n    if (or) {\n      typ.tokens.separator = or;\n    }\n    else break;\n  }\n  if (ret.idlType.length < 2) {\n    tokeniser.error(\"At least two types are expected in a union type but found less\");\n  }\n  tokens.close = tokeniser.consume(\")\") || tokeniser.error(\"Unterminated union type\");\n  type_suffix(tokeniser, ret);\n  return ret;\n}\n\nexport class Type extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   * @param {string} typeName\n   */\n  static parse(tokeniser, typeName) {\n    return single_type(tokeniser, typeName) || union_type(tokeniser, typeName);\n  }\n\n  constructor({ source, tokens }) {\n    super({ source, tokens });\n    Object.defineProperty(this, \"subtype\", { value: [] });\n    this.extAttrs = [];\n  }\n\n  get generic() {\n    if (this.subtype.length && this.tokens.base) {\n      return this.tokens.base.value;\n    }\n    return \"\";\n  }\n  get nullable() {\n    return Boolean(this.tokens.nullable);\n  }\n  get union() {\n    return Boolean(this.subtype.length) && !this.tokens.base;\n  }\n  get idlType() {\n    if (this.subtype.length) {\n      return this.subtype;\n    }\n    // Adding prefixes/postfixes for \"unrestricted float\", etc.\n    const name = [\n      this.tokens.prefix,\n      this.tokens.base,\n      this.tokens.postfix\n    ].filter(t => t).map(t => t.value).join(\" \");\n    return unescape(name);\n  }\n\n  *validate(defs) {\n    /*\n     * If a union is nullable, its subunions cannot include a dictionary\n     * If not, subunions may include dictionaries if each union is not nullable\n     */\n    const typedef = !this.union && defs.unique.get(this.idlType);\n    const target =\n      this.union ? this :\n      (typedef && typedef.type === \"typedef\") ? typedef.idlType :\n      undefined;\n    if (target && this.nullable) {\n      // do not allow any dictionary\n      const reference = idlTypeIncludesDictionary(target, defs);\n      if (reference) {\n        const targetToken = (this.union ? reference : this).tokens.base;\n        const message = `Nullable union cannot include a dictionary type`;\n        yield validationError(this.source, targetToken, this, message);\n      }\n    } else {\n      // allow some dictionary\n      for (const subtype of this.subtype) {\n        yield* subtype.validate(defs);\n      }\n    }\n  }\n}\n","import { Base } from \"./base.js\";\nimport { const_data, const_value } from \"./helpers.js\";\n\nexport class Default extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const assign = tokeniser.consume(\"=\");\n    if (!assign) {\n      return null;\n    }\n    const def = const_value(tokeniser) || tokeniser.consume(\"string\", \"null\", \"[\", \"{\") || tokeniser.error(\"No value for default\");\n    const expression = [def];\n    if (def.type === \"[\") {\n      const close = tokeniser.consume(\"]\") || tokeniser.error(\"Default sequence value must be empty\");\n      expression.push(close);\n    } else if (def.type === \"{\") {\n      const close = tokeniser.consume(\"}\") || tokeniser.error(\"Default dictionary value must be empty\");\n      expression.push(close);\n    }\n    return new Default({ source: tokeniser.source, tokens: { assign }, expression });\n  }\n\n  constructor({ source, tokens, expression }) {\n    super({ source, tokens });\n    Object.defineProperty(this, \"expression\", { value: expression });\n  }\n\n  get type() {\n    return const_data(this.expression[0]).type;\n  }\n  get value() {\n    return const_data(this.expression[0]).value;\n  }\n  get negative() {\n    return const_data(this.expression[0]).negative;\n  }\n}\n","export class ArrayBase extends Array {\n  constructor({ source, tokens }) {\n    super();\n    Object.defineProperties(this, {\n      source: { value: source },\n      tokens: { value: tokens }\n    });\n  }\n}\n","import { Base } from \"./base.js\";\nimport { ArrayBase } from \"./array-base.js\";\nimport { list, identifiers, argument_list } from \"./helpers.js\";\nimport { validationError } from \"../error.js\";\n\nclass ExtendedAttributeParameters extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = { assign: tokeniser.consume(\"=\") };\n    const ret = new ExtendedAttributeParameters({ source: tokeniser.source, tokens });\n    if (tokens.assign) {\n      tokens.secondaryName = tokeniser.consume(\"identifier\", \"decimal\", \"integer\", \"string\");\n    }\n    tokens.open = tokeniser.consume(\"(\");\n    if (tokens.open) {\n      ret.list = ret.rhsType === \"identifier-list\" ?\n        // [Exposed=(Window,Worker)]\n        identifiers(tokeniser) :\n        // [NamedConstructor=Audio(DOMString src)] or [Constructor(DOMString str)]\n        argument_list(tokeniser);\n      tokens.close = tokeniser.consume(\")\") || tokeniser.error(\"Unexpected token in extended attribute argument list\");\n    } else if (ret.hasRhs && !tokens.secondaryName) {\n      tokeniser.error(\"No right hand side to extended attribute assignment\");\n    }\n    return ret;\n  }\n\n  get rhsType() {\n    return !this.tokens.assign ? null :\n      !this.tokens.secondaryName ? \"identifier-list\" :\n        this.tokens.secondaryName.type;\n  }\n}\n\nexport class SimpleExtendedAttribute extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const name = tokeniser.consume(\"identifier\");\n    if (name) {\n      return new SimpleExtendedAttribute({\n        source: tokeniser.source,\n        tokens: { name },\n        params: ExtendedAttributeParameters.parse(tokeniser)\n      });\n    }\n  }\n\n  constructor({ source, tokens, params }) {\n    super({ source, tokens });\n    Object.defineProperty(this, \"params\", { value: params });\n  }\n\n  get type() {\n    return \"extended-attribute\";\n  }\n  get name() {\n    return this.tokens.name.value;\n  }\n  get rhs() {\n    const { rhsType: type, tokens, list } = this.params;\n    if (!type) {\n      return null;\n    }\n    const value = type === \"identifier-list\" ? list : tokens.secondaryName.value;\n    return { type, value };\n  }\n  get arguments() {\n    const { rhsType, list } = this.params;\n    if (!list || rhsType === \"identifier-list\") {\n      return [];\n    }\n    return list;\n  }\n\n  *validate(defs) {\n    if (this.name === \"NoInterfaceObject\") {\n      const message = `\\`[NoInterfaceObject]\\` extended attribute is an \\\nundesirable feature that may be removed from Web IDL in the future. Refer to the \\\n[relevant upstream PR](https://github.com/heycam/webidl/pull/609) for more \\\ninformation.`;\n      yield validationError(this.source, this.tokens.name, this, message, { level: \"warning\" });\n    }\n    for (const arg of this.arguments) {\n      yield* arg.validate(defs);\n    }\n  }\n}\n\n// Note: we parse something simpler than the official syntax. It's all that ever\n// seems to be used\nexport class ExtendedAttributes extends ArrayBase {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = {};\n    tokens.open = tokeniser.consume(\"[\");\n    if (!tokens.open) return new ExtendedAttributes({});\n    const ret = new ExtendedAttributes({ source: tokeniser.source, tokens });\n    ret.push(...list(tokeniser, {\n      parser: SimpleExtendedAttribute.parse,\n      listName: \"extended attribute\"\n    }));\n    tokens.close = tokeniser.consume(\"]\") || tokeniser.error(\"Unexpected closing token of extended attribute\");\n    if (!ret.length) {\n      tokeniser.error(\"Found an empty extended attribute\");\n    }\n    if (tokeniser.probe(\"[\")) {\n      tokeniser.error(\"Illegal double extended attribute lists, consider merging them\");\n    }\n    return ret;\n  }\n\n  *validate(defs) {\n    for (const extAttr of this) {\n      yield* extAttr.validate(defs);\n    }\n  }\n}\n","import { Type } from \"./type.js\";\nimport { Argument } from \"./argument.js\";\nimport { Token } from \"./token.js\";\nimport { ExtendedAttributes, SimpleExtendedAttribute } from \"./extended-attributes.js\";\nimport { Operation } from \"./operation.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Tokeniser } from \"../tokeniser.js\";\n\n/**\n * @param {string} identifier\n */\nexport function unescape(identifier) {\n  return identifier.startsWith('_') ? identifier.slice(1) : identifier;\n}\n\n/**\n * Parses comma-separated list\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {object} args\n * @param {Function} args.parser parser function for each item\n * @param {boolean} [args.allowDangler] whether to allow dangling comma\n * @param {string} [args.listName] the name to be shown on error messages\n */\nexport function list(tokeniser, { parser, allowDangler, listName = \"list\" }) {\n  const first = parser(tokeniser);\n  if (!first) {\n    return [];\n  }\n  first.tokens.separator = tokeniser.consume(\",\");\n  const items = [first];\n  while (first.tokens.separator) {\n    const item = parser(tokeniser);\n    if (!item) {\n      if (!allowDangler) {\n        tokeniser.error(`Trailing comma in ${listName}`);\n      }\n      break;\n    }\n    item.tokens.separator = tokeniser.consume(\",\");\n    items.push(item);\n    if (!item.tokens.separator) break;\n  }\n  return items;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nexport function const_value(tokeniser) {\n  return tokeniser.consume(\"true\", \"false\", \"Infinity\", \"-Infinity\", \"NaN\", \"decimal\", \"integer\");\n}\n\n/**\n * @param {object} token\n * @param {string} token.type\n * @param {string} token.value\n */\nexport function const_data({ type, value }) {\n  switch (type) {\n    case \"true\":\n    case \"false\":\n      return { type: \"boolean\", value: type === \"true\" };\n    case \"Infinity\":\n    case \"-Infinity\":\n      return { type: \"Infinity\", negative: type.startsWith(\"-\") };\n    case \"[\":\n      return { type: \"sequence\", value: [] };\n    case \"{\":\n      return { type: \"dictionary\" };\n    case \"decimal\":\n    case \"integer\":\n      return { type: \"number\", value };\n    case \"string\":\n      return { type: \"string\", value: value.slice(1, -1) };\n    default:\n      return { type };\n  }\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nexport function primitive_type(tokeniser) {\n  function integer_type() {\n    const prefix = tokeniser.consume(\"unsigned\");\n    const base = tokeniser.consume(\"short\", \"long\");\n    if (base) {\n      const postfix = tokeniser.consume(\"long\");\n      return new Type({ source, tokens: { prefix, base, postfix } });\n    }\n    if (prefix) tokeniser.error(\"Failed to parse integer type\");\n  }\n\n  function decimal_type() {\n    const prefix = tokeniser.consume(\"unrestricted\");\n    const base = tokeniser.consume(\"float\", \"double\");\n    if (base) {\n      return new Type({ source, tokens: { prefix, base } });\n    }\n    if (prefix) tokeniser.error(\"Failed to parse float type\");\n  }\n\n  const { source } = tokeniser;\n  const num_type = integer_type(tokeniser) || decimal_type(tokeniser);\n  if (num_type) return num_type;\n  const base = tokeniser.consume(\"boolean\", \"byte\", \"octet\");\n  if (base) {\n    return new Type({ source, tokens: { base } });\n  }\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nexport function identifiers(tokeniser) {\n  const ids = list(tokeniser, { parser: Token.parser(tokeniser, \"identifier\"), listName: \"identifier list\" });\n  if (!ids.length) {\n    tokeniser.error(\"Expected identifiers but none found\");\n  }\n  return ids;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nexport function argument_list(tokeniser) {\n  return list(tokeniser, { parser: Argument.parse, listName: \"arguments list\" });\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nexport function type_with_extended_attributes(tokeniser, typeName) {\n  const extAttrs = ExtendedAttributes.parse(tokeniser);\n  const ret = Type.parse(tokeniser, typeName);\n  if (ret) ret.extAttrs = extAttrs;\n  return ret;\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n * @param {string} typeName\n */\nexport function return_type(tokeniser, typeName) {\n  const typ = Type.parse(tokeniser, typeName || \"return-type\");\n  if (typ) {\n    return typ;\n  }\n  const voidToken = tokeniser.consume(\"void\");\n  if (voidToken) {\n    const ret = new Type({ source: tokeniser.source, tokens: { base: voidToken } });\n    ret.type = \"return-type\";\n    return ret;\n  }\n}\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nexport function stringifier(tokeniser) {\n  const special = tokeniser.consume(\"stringifier\");\n  if (!special) return;\n  const member = Attribute.parse(tokeniser, { special }) ||\n    Operation.parse(tokeniser, { special }) ||\n    tokeniser.error(\"Unterminated stringifier\");\n  return member;\n}\n\n/**\n * @param {object} def\n * @param {import(\"./extended-attributes.js\").ExtendedAttributes} def.extAttrs\n */\nexport function autofixAddExposedWindow(def) {\n  return () => {\n    if (def.extAttrs.length){\n      const tokeniser = new Tokeniser(\"Exposed=Window,\");\n      const exposed = SimpleExtendedAttribute.parse(tokeniser);\n      exposed.tokens.separator = tokeniser.consume(\",\");\n      const existing = def.extAttrs[0];\n      if (!/^\\s/.test(existing.tokens.name.trivia)) {\n        existing.tokens.name.trivia = ` ${existing.tokens.name.trivia}`;\n      }\n      def.extAttrs.unshift(exposed);\n    } else {\n      def.extAttrs = ExtendedAttributes.parse(new Tokeniser(\"[Exposed=Window]\"));\n      def.extAttrs.tokens.open.trivia = def.tokens.base.trivia;\n      def.tokens.base.trivia = \" \";\n    }\n  };\n}\n","import { Base } from \"./base.js\";\nimport { Default } from \"./default.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\nimport { unescape, type_with_extended_attributes } from \"./helpers.js\";\nimport { argumentNameKeywords, Tokeniser } from \"../tokeniser.js\";\nimport { validationError } from \"../error.js\";\nimport { idlTypeIncludesDictionary } from \"../validators/helpers.js\";\n\nexport class Argument extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const start_position = tokeniser.position;\n    const tokens = {};\n    const ret = new Argument({ source: tokeniser.source, tokens });\n    ret.extAttrs = ExtendedAttributes.parse(tokeniser);\n    tokens.optional = tokeniser.consume(\"optional\");\n    ret.idlType = type_with_extended_attributes(tokeniser, \"argument-type\");\n    if (!ret.idlType) {\n      return tokeniser.unconsume(start_position);\n    }\n    if (!tokens.optional) {\n      tokens.variadic = tokeniser.consume(\"...\");\n    }\n    tokens.name = tokeniser.consume(\"identifier\", ...argumentNameKeywords);\n    if (!tokens.name) {\n      return tokeniser.unconsume(start_position);\n    }\n    ret.default = tokens.optional ? Default.parse(tokeniser) : null;\n    return ret;\n  }\n\n  get type() {\n    return \"argument\";\n  }\n  get optional() {\n    return !!this.tokens.optional;\n  }\n  get variadic() {\n    return !!this.tokens.variadic;\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  *validate(defs) {\n    yield* this.idlType.validate(defs);\n    if (idlTypeIncludesDictionary(this.idlType, defs)) {\n      if (this.optional && !this.default) {\n        const message = `Optional dictionary arguments must have a default value of \\`{}\\`.`;\n        yield validationError(this.source, this.tokens.name, this, message, {\n          autofix: autofixOptionalDictionaryDefaultValue(this)\n        });\n      }\n      if (this.idlType.nullable) {\n        const message = `Dictionary arguments cannot be nullable.`;\n        yield validationError(this.source, this.tokens.name, this, message);\n      }\n    }\n  }\n}\n\n/**\n * @param {Argument} arg\n */\nfunction autofixOptionalDictionaryDefaultValue(arg) {\n  return () => {\n    arg.default = Default.parse(new Tokeniser(\" = {}\"));\n  };\n}\n","import { Base } from \"./base.js\";\n\nexport class Token extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   * @param {string} type\n   */\n  static parser(tokeniser, type) {\n    return () => {\n      const value = tokeniser.consume(type);\n      if (value) {\n        return new Token({ source: tokeniser.source, tokens: { value } });\n      }\n    };\n  }\n\n  get value() {\n    return this.tokens.value.value;\n  }\n}\n","import { Base } from \"./base.js\";\nimport { return_type, argument_list, unescape } from \"./helpers.js\";\n\nexport class Operation extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser, { special, regular } = {}) {\n    const tokens = { special };\n    const ret = new Operation({ source: tokeniser.source, tokens });\n    if (special && special.value === \"stringifier\") {\n      tokens.termination = tokeniser.consume(\";\");\n      if (tokens.termination) {\n        ret.arguments = [];\n        return ret;\n      }\n    }\n    if (!special && !regular) {\n      tokens.special = tokeniser.consume(\"getter\", \"setter\", \"deleter\");\n    }\n    ret.idlType = return_type(tokeniser) || tokeniser.error(\"Missing return type\");\n    tokens.name = tokeniser.consume(\"identifier\", \"includes\");\n    tokens.open = tokeniser.consume(\"(\") || tokeniser.error(\"Invalid operation\");\n    ret.arguments = argument_list(tokeniser);\n    tokens.close = tokeniser.consume(\")\") || tokeniser.error(\"Unterminated operation\");\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"Unterminated operation, expected `;`\");\n    return ret;\n  }\n\n  get type() {\n    return \"operation\";\n  }\n  get name() {\n    const { name } = this.tokens;\n    if (!name) {\n      return \"\";\n    }\n    return unescape(name.value);\n  }\n  get special() {\n    if (!this.tokens.special) {\n      return \"\";\n    }\n    return this.tokens.special.value;\n  }\n\n  *validate(defs) {\n    if (this.idlType) {\n      yield* this.idlType.validate(defs);\n    }\n    for (const argument of this.arguments) {\n      yield* argument.validate(defs);\n    }\n  }\n}\n","import { Base } from \"./base.js\";\nimport { type_with_extended_attributes, unescape } from \"./helpers.js\";\n\nexport class Attribute extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser, { special, noInherit = false, readonly = false } = {}) {\n    const start_position = tokeniser.position;\n    const tokens = { special };\n    const ret = new Attribute({ source: tokeniser.source, tokens });\n    if (!special && !noInherit) {\n      tokens.special = tokeniser.consume(\"inherit\");\n    }\n    if (ret.special === \"inherit\" && tokeniser.probe(\"readonly\")) {\n      tokeniser.error(\"Inherited attributes cannot be read-only\");\n    }\n    tokens.readonly = tokeniser.consume(\"readonly\");\n    if (readonly && !tokens.readonly && tokeniser.probe(\"attribute\")) {\n      tokeniser.error(\"Attributes must be readonly in this context\");\n    }\n    tokens.base = tokeniser.consume(\"attribute\");\n    if (!tokens.base) {\n      tokeniser.unconsume(start_position);\n      return;\n    }\n    ret.idlType = type_with_extended_attributes(tokeniser, \"attribute-type\") || tokeniser.error(\"Attribute lacks a type\");\n    switch (ret.idlType.generic) {\n      case \"sequence\":\n      case \"record\": tokeniser.error(`Attributes cannot accept ${ret.idlType.generic} types`);\n    }\n    tokens.name = tokeniser.consume(\"identifier\", \"async\", \"required\") || tokeniser.error(\"Attribute lacks a name\");\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"Unterminated attribute, expected `;`\");\n    return ret;\n  }\n\n  get type() {\n    return \"attribute\";\n  }\n  get special() {\n    if (!this.tokens.special) {\n      return \"\";\n    }\n    return this.tokens.special.value;\n  }\n  get readonly() {\n    return !!this.tokens.readonly;\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  *validate(defs) {\n    yield* this.idlType.validate(defs);\n  }\n}\n","import { list, unescape } from \"./helpers.js\";\nimport { Token } from \"./token.js\";\nimport { Base } from \"./base.js\";\n\nclass EnumValue extends Token {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const value = tokeniser.consume(\"string\");\n    if (value) {\n      return new EnumValue({ source: tokeniser.source, tokens: { value } });\n    }\n  }\n\n  get type() {\n    return \"enum-value\";\n  }\n  get value() {\n    return super.value.slice(1, -1);\n  }\n}\n\nexport class Enum extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = {};\n    tokens.base = tokeniser.consume(\"enum\");\n    if (!tokens.base) {\n      return;\n    }\n    tokens.name = tokeniser.consume(\"identifier\") || tokeniser.error(\"No name for enum\");\n    const ret = tokeniser.current = new Enum({ source: tokeniser.source, tokens });\n    tokens.open = tokeniser.consume(\"{\") || tokeniser.error(\"Bodyless enum\");\n    ret.values = list(tokeniser, {\n      parser: EnumValue.parse,\n      allowDangler: true,\n      listName: \"enumeration\"\n    });\n    if (tokeniser.probe(\"string\")) {\n      tokeniser.error(\"No comma between enum values\");\n    }\n    tokens.close = tokeniser.consume(\"}\") || tokeniser.error(\"Unexpected value in enum\");\n    if (!ret.values.length) {\n      tokeniser.error(\"No value in enum\");\n    }\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"No semicolon after enum\");\n    return ret;\n  }\n\n  get type() {\n    return \"enum\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n}\n","import { Base } from \"./base.js\";\nimport { unescape } from \"./helpers.js\";\n\nexport class Includes extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const target = tokeniser.consume(\"identifier\");\n    if (!target) {\n      return;\n    }\n    const tokens = { target };\n    tokens.includes = tokeniser.consume(\"includes\");\n    if (!tokens.includes) {\n      tokeniser.unconsume(target.index);\n      return;\n    }\n    tokens.mixin = tokeniser.consume(\"identifier\") || tokeniser.error(\"Incomplete includes statement\");\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"No terminating ; for includes statement\");\n    return new Includes({ source: tokeniser.source, tokens });\n  }\n\n  get type() {\n    return \"includes\";\n  }\n  get target() {\n    return unescape(this.tokens.target.value);\n  }\n  get includes() {\n    return unescape(this.tokens.mixin.value);\n  }\n}\n","import { Base } from \"./base.js\";\nimport { type_with_extended_attributes, unescape } from \"./helpers.js\";\n\nexport class Typedef extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = {};\n    const ret = new Typedef({ source: tokeniser.source, tokens });\n    tokens.base = tokeniser.consume(\"typedef\");\n    if (!tokens.base) {\n      return;\n    }\n    ret.idlType = type_with_extended_attributes(tokeniser, \"typedef-type\") || tokeniser.error(\"Typedef lacks a type\");\n    tokens.name = tokeniser.consume(\"identifier\") || tokeniser.error(\"Typedef lacks a name\");\n    tokeniser.current = ret;\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"Unterminated typedef, expected `;`\");\n    return ret;\n  }\n\n  get type() {\n    return \"typedef\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  *validate(defs) {\n    yield* this.idlType.validate(defs);\n  }\n}\n","import { Base } from \"./base.js\";\nimport { return_type, argument_list, unescape } from \"./helpers.js\";\n\nexport class CallbackFunction extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser, base) {\n    const tokens = { base };\n    const ret = new CallbackFunction({ source: tokeniser.source, tokens });\n    tokens.name = tokeniser.consume(\"identifier\") || tokeniser.error(\"Callback lacks a name\");\n    tokeniser.current = ret;\n    tokens.assign = tokeniser.consume(\"=\") || tokeniser.error(\"Callback lacks an assignment\");\n    ret.idlType = return_type(tokeniser) || tokeniser.error(\"Callback lacks a return type\");\n    tokens.open = tokeniser.consume(\"(\") || tokeniser.error(\"Callback lacks parentheses for arguments\");\n    ret.arguments = argument_list(tokeniser);\n    tokens.close = tokeniser.consume(\")\") || tokeniser.error(\"Unterminated callback\");\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"Unterminated callback, expected `;`\");\n    return ret;\n  }\n\n  get type() {\n    return \"callback\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n\n  *validate(defs) {\n    yield* this.idlType.validate(defs);\n  }\n}\n","import { Base } from \"./base.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\nimport { unescape } from \"./helpers.js\";\n\n/**\n * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n */\nfunction inheritance(tokeniser) {\n  const colon = tokeniser.consume(\":\");\n  if (!colon) {\n    return {};\n  }\n  const inheritance = tokeniser.consume(\"identifier\") || tokeniser.error(\"Inheritance lacks a type\");\n  return { colon, inheritance };\n}\n\nexport class Container extends Base {\n    /**\n     * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n     * @param {*} instance\n     * @param {*} args\n     */\n    ////add argument enableMozillaBodylessInterface to parse(tokeniser, instance, { type, inheritable, allowedMembers})\n    static parse(tokeniser, instance, { type, inheritable, allowedMembers,enableMozillaBodylessInterface }) {\n      const { tokens } = instance;\n      tokens.name = tokeniser.consume(\"identifier\") || tokeniser.error(`Missing name in ${instance.type}`);\n      tokeniser.current = instance;\n      if (inheritable) {\n        Object.assign(tokens, inheritance(tokeniser));\n      }\n      ////\n      ////console.log(enableMozillaBodylessInterface)\n      ////\n      /*permit Bodyless*/\n      tokens.open = tokeniser.consume(\"{\")\n      if(!tokens.open && (enableMozillaBodylessInterface===true)) {\n          tokens.termination = tokeniser.consume(\";\") || tokeniser.error(`Missing semicolon after ${type}`);\n          return instance;\n      } else  {\n          tokens.open ||  tokeniser.error(`Bodyless ${type}`);\n      } \n      /**/      \n      ////tokens.open = tokeniser.consume(\"{\") || tokeniser.error(`Bodyless ${type}`);\n      instance.members = [];\n      while (true) {\n        tokens.close = tokeniser.consume(\"}\");\n        if (tokens.close) {\n          tokens.termination = tokeniser.consume(\";\") || tokeniser.error(`Missing semicolon after ${type}`);\n          return instance;\n        }\n        const ea = ExtendedAttributes.parse(tokeniser);\n        let mem;\n        for (const [parser, ...args] of allowedMembers) {\n          mem = parser(tokeniser, ...args);\n          if (mem) {\n            break;\n          }\n        }\n        if (!mem) {\n          tokeniser.error(\"Unknown member\");\n        }\n        mem.extAttrs = ea;\n        instance.members.push(mem);\n      }\n    }\n\n    get partial() {\n      return !!this.tokens.partial;\n    }\n    get name() {\n      return unescape(this.tokens.name.value);\n    }\n    get inheritance() {\n      if (!this.tokens.inheritance) {\n        return null;\n      }\n      return unescape(this.tokens.inheritance.value);\n    }\n\n    *validate(defs) {\n      for (const member of this.members) {\n        if (member.validate) {\n          yield* member.validate(defs);\n        }\n      }\n    }\n  }\n","import { Base } from \"./base.js\";\nimport { Type } from \"./type.js\";\nimport { const_data, const_value, primitive_type } from \"./helpers.js\";\n\nexport class Constant extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = {};\n    tokens.base = tokeniser.consume(\"const\");\n    if (!tokens.base) {\n      return;\n    }\n    let idlType = primitive_type(tokeniser);\n    if (!idlType) {\n      const base = tokeniser.consume(\"identifier\") || tokeniser.error(\"Const lacks a type\");\n      idlType = new Type({ source: tokeniser.source, tokens: { base } });\n    }\n    if (tokeniser.probe(\"?\")) {\n      tokeniser.error(\"Unexpected nullable constant type\");\n    }\n    idlType.type = \"const-type\";\n    tokens.name = tokeniser.consume(\"identifier\") || tokeniser.error(\"Const lacks a name\");\n    tokens.assign = tokeniser.consume(\"=\") || tokeniser.error(\"Const lacks value assignment\");\n    tokens.value = const_value(tokeniser) || tokeniser.error(\"Const lacks a value\");\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"Unterminated const, expected `;`\");\n    const ret = new Constant({ source: tokeniser.source, tokens });\n    ret.idlType = idlType;\n    return ret;\n  }\n\n  get type() {\n    return \"const\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n  get value() {\n    return const_data(this.tokens.value);\n  }\n}\n","import { Base } from \"./base.js\";\nimport { type_with_extended_attributes } from \"./helpers.js\";\n\nexport class IterableLike extends Base {\n  /**\n   * @param {import(\"../tokeniser.js\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const start_position = tokeniser.position;\n    const tokens = {};\n    const ret = new IterableLike({ source: tokeniser.source, tokens });\n    tokens.readonly = tokeniser.consume(\"readonly\");\n    if (!tokens.readonly) {\n      tokens.async = tokeniser.consume(\"async\");\n    }\n    tokens.base =\n      tokens.readonly ? tokeniser.consume(\"maplike\", \"setlike\") :\n      tokens.async ? tokeniser.consume(\"iterable\") :\n      tokeniser.consume(\"iterable\", \"maplike\", \"setlike\");\n    if (!tokens.base) {\n      tokeniser.unconsume(start_position);\n      return;\n    }\n\n    const { type } = ret;\n    const secondTypeRequired = type === \"maplike\" || ret.async;\n    const secondTypeAllowed = secondTypeRequired || type === \"iterable\";\n\n    tokens.open = tokeniser.consume(\"<\") || tokeniser.error(`Missing less-than sign \\`<\\` in ${type} declaration`);\n    const first = type_with_extended_attributes(tokeniser) || tokeniser.error(`Missing a type argument in ${type} declaration`);\n    ret.idlType = [first];\n    if (secondTypeAllowed) {\n      first.tokens.separator = tokeniser.consume(\",\");\n      if (first.tokens.separator) {\n        ret.idlType.push(type_with_extended_attributes(tokeniser));\n      }\n      else if (secondTypeRequired) {\n        tokeniser.error(`Missing second type argument in ${type} declaration`);\n      }\n    }\n    tokens.close = tokeniser.consume(\">\") || tokeniser.error(`Missing greater-than sign \\`>\\` in ${type} declaration`);\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(`Missing semicolon after ${type} declaration`);\n\n    return ret;\n  }\n\n  get type() {\n    return this.tokens.base.value;\n  }\n  get readonly() {\n    return !!this.tokens.readonly;\n  }\n  get async() {\n    return !!this.tokens.async;\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Operation } from \"./operation.js\";\nimport { Constant } from \"./constant.js\";\nimport { IterableLike } from \"./iterable.js\";\nimport { stringifier, autofixAddExposedWindow } from \"./helpers.js\";\nimport { validationError } from \"../error.js\";\nimport { checkInterfaceMemberDuplication } from \"../validators/interface.js\";\n\n/**\n * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n */\nfunction static_member(tokeniser) {\n  const special = tokeniser.consume(\"static\");\n  if (!special) return;\n  const member = Attribute.parse(tokeniser, { special }) ||\n    Operation.parse(tokeniser, { special }) ||\n    tokeniser.error(\"No body in static member\");\n  return member;\n}\n\nexport class Interface extends Container {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */ \n\n  ////add argument enableMozillaBodylessInterface\n  static parse(tokeniser, base, { partial = null ,enableMozillaBodylessInterface} = {}) {\n    ////\n    console.log(\"interface: \",enableMozillaBodylessInterface)\n    ////\n    const tokens = { partial, base };\n    return Container.parse(tokeniser, new Interface({ source: tokeniser.source, tokens }), {\n      type: \"interface\",\n      inheritable: !partial,\n      allowedMembers: [\n        [Constant.parse],\n        [static_member],\n        [stringifier],\n        [IterableLike.parse],\n        [Attribute.parse],\n        [Operation.parse]\n      ],\n      ////\n      enableMozillaBodylessInterface\n    });\n  }\n\n  get type() {\n    return \"interface\";\n  }\n\n  *validate(defs) {\n    yield* this.extAttrs.validate(defs);\n    if (\n      !this.partial &&\n      this.extAttrs.every(extAttr => extAttr.name !== \"Exposed\") &&\n      this.extAttrs.every(extAttr => extAttr.name !== \"NoInterfaceObject\")\n    ) {\n      const message = `Interfaces must have \\`[Exposed]\\` extended attribute. \\\nTo fix, add, for example, \\`[Exposed=Window]\\`. Please also consider carefully \\\nif your interface should also be exposed in a Worker scope. Refer to the \\\n[WebIDL spec section on Exposed](https://heycam.github.io/webidl/#Exposed) \\\nfor more information.`;\n      yield validationError(this.source, this.tokens.name, this, message, {\n        autofix: autofixAddExposedWindow(this)\n      });\n    }\n\n    yield* super.validate(defs);\n    if (!this.partial) {\n      yield* checkInterfaceMemberDuplication(defs, this);\n    }\n  }\n}\n","import { validationError } from \"../error.js\";\n\nexport function* checkInterfaceMemberDuplication(defs, i) {\n  const opNames = new Set(getOperations(i).map(op => op.name));\n  const partials = defs.partials.get(i.name) || [];\n  const mixins = defs.mixinMap.get(i.name) || [];\n  for (const ext of [...partials, ...mixins]) {\n    const additions = getOperations(ext);\n    yield* forEachExtension(additions, opNames, ext, i);\n    for (const addition of additions) {\n      opNames.add(addition.name);\n    }\n  }\n\n  function* forEachExtension(additions, existings, ext, base) {\n    for (const addition of additions) {\n      const { name } = addition;\n      if (name && existings.has(name)) {\n        const message = `The operation \"${name}\" has already been defined for the base interface \"${base.name}\" either in itself or in a mixin`;\n        yield validationError(ext.source, addition.tokens.name, ext, message);\n      }\n    }\n  }\n\n  function getOperations(i) {\n    return i.members\n      .filter(({type}) => type === \"operation\");\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Constant } from \"./constant.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Operation } from \"./operation.js\";\nimport { stringifier } from \"./helpers.js\";\n\nexport class Mixin extends Container {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser, base, { partial } = {}) {\n    const tokens = { partial, base };\n    tokens.mixin = tokeniser.consume(\"mixin\");\n    if (!tokens.mixin) {\n      return;\n    }\n    return Container.parse(tokeniser, new Mixin({ source: tokeniser.source, tokens }), {\n      type: \"interface mixin\",\n      allowedMembers: [\n        [Constant.parse],\n        [stringifier],\n        [Attribute.parse, { noInherit: true }],\n        [Operation.parse, { regular: true }]\n      ]\n    });\n  }\n\n  get type() {\n    return \"interface mixin\";\n  }\n}\n","import { Base } from \"./base.js\";\nimport { unescape, type_with_extended_attributes } from \"./helpers.js\";\nimport { ExtendedAttributes } from \"./extended-attributes.js\";\nimport { Default } from \"./default.js\";\n\nexport class Field extends Base {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser) {\n    const tokens = {};\n    const ret = new Field({ source: tokeniser.source, tokens });\n    ret.extAttrs = ExtendedAttributes.parse(tokeniser);\n    tokens.required = tokeniser.consume(\"required\");\n    ret.idlType = type_with_extended_attributes(tokeniser, \"dictionary-type\") || tokeniser.error(\"Dictionary member lacks a type\");\n    tokens.name = tokeniser.consume(\"identifier\") || tokeniser.error(\"Dictionary member lacks a name\");\n    ret.default = Default.parse(tokeniser);\n    if (tokens.required && ret.default) tokeniser.error(\"Required member must not have a default\");\n    tokens.termination = tokeniser.consume(\";\") || tokeniser.error(\"Unterminated dictionary member, expected `;`\");\n    return ret;\n  }\n\n  get type() {\n    return \"field\";\n  }\n  get name() {\n    return unescape(this.tokens.name.value);\n  }\n  get required() {\n    return !!this.tokens.required;\n  }\n\n  *validate(defs) {\n    yield* this.idlType.validate(defs);\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Field } from \"./field.js\";\n\nexport class Dictionary extends Container {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser, { partial } = {}) {\n    const tokens = { partial };\n    tokens.base = tokeniser.consume(\"dictionary\");\n    if (!tokens.base) {\n      return;\n    }\n    return Container.parse(tokeniser, new Dictionary({ source: tokeniser.source, tokens }), {\n      type: \"dictionary\",\n      inheritable: !partial,\n      allowedMembers: [\n        [Field.parse],\n      ]\n    });\n  }\n\n  get type() {\n    return \"dictionary\";\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Attribute } from \"./attribute.js\";\nimport { Operation } from \"./operation.js\";\nimport { validationError } from \"../error.js\";\nimport { autofixAddExposedWindow } from \"./helpers.js\";\n\n\nimport {Constant} from \"./constant.js\";\n////import Constant  for  adding Constant.parse to allowedMembers\n\n\n\nexport class Namespace extends Container {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser, { partial,enableMozillaNamespacesConstants } = {}) {\n    ////\n    console.log(\"namespace :\",enableMozillaNamespacesConstants)\n    ////\n    //// add argument  options.enableMozillaNamespacesConstants to parse\n    const tokens = { partial };\n    tokens.base = tokeniser.consume(\"namespace\");\n    if (!tokens.base) {\n      return;\n    }\n    /*for enable-mozilla-namespaces-constants*/\n    let allowedMembers;\n    if(enableMozillaNamespacesConstants === true) {\n        allowedMembers = [\n          [Constant.parse],\n          ////add const parse \n          [Attribute.parse, { noInherit: true, readonly: true }],\n          [Operation.parse, { regular: true }],\n         ]\n    } else {\n        allowedMembers = [\n          [Attribute.parse, { noInherit: true, readonly: true }],\n          [Operation.parse, { regular: true }],\n         ]\n\n    }\n    return Container.parse(tokeniser, new Namespace({ source: tokeniser.source, tokens }), {\n      type: \"namespace\",\n      allowedMembers: allowedMembers\n      ////depends on (enableMozillaNamespacesConstants === true)\n    });\n  }\n\n  get type() {\n    return \"namespace\";\n  }\n\n  *validate(defs) {\n    if (!this.partial && this.extAttrs.every(extAttr => extAttr.name !== \"Exposed\")) {\n      const message = `Namespaces must have [Exposed] extended attribute. \\\nTo fix, add, for example, [Exposed=Window]. Please also consider carefully \\\nif your namespace should also be exposed in a Worker scope. Refer to the \\\n[WebIDL spec section on Exposed](https://heycam.github.io/webidl/#Exposed) \\\nfor more information.`;\n      yield validationError(this.source, this.tokens.name, this, message, {\n        autofix: autofixAddExposedWindow(this)\n      });\n    }\n    yield* super.validate(defs);\n  }\n}\n","import { Container } from \"./container.js\";\nimport { Operation } from \"./operation.js\";\nimport { Constant } from \"./constant.js\";\n\n\nexport class CallbackInterface extends Container {\n  /**\n   * @param {import(\"../tokeniser\").Tokeniser} tokeniser\n   */\n  static parse(tokeniser, callback, { partial = null } = {}) {\n    const tokens = { callback };\n    tokens.base = tokeniser.consume(\"interface\");\n    if (!tokens.base) {\n      return;\n    }\n    return Container.parse(tokeniser, new CallbackInterface({ source: tokeniser.source, tokens }), {\n      type: \"callback interface\",\n      inheritable: !partial,\n      allowedMembers: [\n        [Constant.parse],\n        [Operation.parse, { regular: true }]\n      ]\n    });\n  }\n\n  get type() {\n    return \"callback interface\";\n  }\n}\n","\"use strict\";\n\nimport { Tokeniser } from \"./tokeniser.js\";\nimport { Enum } from \"./productions/enum.js\";\nimport { Includes } from \"./productions/includes.js\";\nimport { ExtendedAttributes } from \"./productions/extended-attributes.js\";\nimport { Typedef } from \"./productions/typedef.js\";\nimport { CallbackFunction } from \"./productions/callback.js\";\nimport { Interface } from \"./productions/interface.js\";\nimport { Mixin } from \"./productions/mixin.js\";\nimport { Dictionary } from \"./productions/dictionary.js\";\nimport { Namespace } from \"./productions/namespace.js\";\nimport { CallbackInterface } from \"./productions/callback-interface.js\";\n\n/**\n * @param {Tokeniser} tokeniser\n * @param {object} options\n * @param {boolean} [options.concrete]\n */\nfunction parseByTokens(tokeniser, options) {\n  const source = tokeniser.source;\n\n  function error(str) {\n    tokeniser.error(str);\n  }\n\n  function consume(...candidates) {\n    return tokeniser.consume(...candidates);\n  }\n\n  function callback() {\n    const callback = consume(\"callback\");\n    if (!callback) return;\n    if (tokeniser.probe(\"interface\")) {\n      return CallbackInterface.parse(tokeniser, callback);\n    }\n    return CallbackFunction.parse(tokeniser, callback);\n  }\n\n  function interface_(opts) {\n    ////\n    ////console.log(\"interface_: \",opts)\n    ////\n    const base = consume(\"interface\");\n    if (!base) return;\n    const ret = Mixin.parse(tokeniser, base, opts) ||\n      Interface.parse(tokeniser, base, opts) ||\n      error(\"Interface has no proper body\");\n    return ret;\n  }\n\n  function partial() {\n    const partial = consume(\"partial\");\n    if (!partial) return;\n    return Dictionary.parse(tokeniser, { partial }) ||\n      interface_({ partial }) ||\n      Namespace.parse(tokeniser, { partial }) ||\n      error(\"Partial doesn't apply to anything\");\n  }\n\n \n  function definition(options) {\n    ////add argument options to definition()\n    return callback() ||\n      ////pass options\n      interface_(options) ||\n      partial() ||\n      Dictionary.parse(tokeniser) ||\n      Enum.parse(tokeniser) ||\n      Typedef.parse(tokeniser) ||\n      Includes.parse(tokeniser) ||\n      Namespace.parse(tokeniser,options);\n      ////add argument options to Namespace.parse(tokeniser)\n  }\n\n  function definitions(options) {\n    ////add argument options to definitions()\n    if (!source.length) return [];\n    const defs = [];\n    while (true) {\n      const ea = ExtendedAttributes.parse(tokeniser);\n      const def = definition(options);\n      ////add argument options to definition()\n      if (!def) {\n        if (ea.length) error(\"Stray extended attributes\");\n        break;\n      }\n      def.extAttrs = ea;\n      defs.push(def);\n    }\n    const eof = consume(\"eof\");\n    if (options.concrete) {\n      defs.push(eof);\n    }\n    return defs;\n  }\n  const res = definitions(options);\n  ////add argument options to definitions()\n  if (tokeniser.position < source.length) error(\"Unrecognised tokens\");\n  return res;\n}\n\nexport function parse(str, options = {}) {\n  ////\n  ////console.log(options)\n  ////\n  const tokeniser = new Tokeniser(str);\n  if (typeof options.sourceName !== \"undefined\") {\n    tokeniser.source.name = options.sourceName;\n  }\n  return parseByTokens(tokeniser, options);\n}\n","\"use strict\";\n\nfunction noop(arg) {\n  return arg;\n}\n\nconst templates = {\n  wrap: items => items.join(\"\"),\n  trivia: noop,\n  name: noop,\n  reference: noop,\n  type: noop,\n  generic: noop,\n  inheritance: noop,\n  definition: noop,\n  extendedAttribute: noop,\n  extendedAttributeReference: noop\n};\n\nexport function write(ast, { templates: ts = templates } = {}) {\n  ts = Object.assign({}, templates, ts);\n\n  function reference(raw, { unescaped, context }) {\n    if (!unescaped) {\n      unescaped = raw.startsWith(\"_\") ? raw.slice(1) : raw;\n    }\n    return ts.reference(raw, unescaped, context);\n  }\n\n  function token(t, wrapper = noop, ...args) {\n    if (!t) {\n      return \"\";\n    }\n    const value = wrapper(t.value, ...args);\n    return ts.wrap([ts.trivia(t.trivia), value]);\n  }\n\n  function reference_token(t, context) {\n    return token(t, reference, { context });\n  }\n\n  function name_token(t, arg) {\n    return token(t, ts.name, arg);\n  }\n\n  function type_body(it) {\n    if (it.union || it.generic) {\n      return ts.wrap([\n        token(it.tokens.base, ts.generic),\n        token(it.tokens.open),\n        ...it.subtype.map(type),\n        token(it.tokens.close)\n      ]);\n    }\n    const firstToken = it.tokens.prefix || it.tokens.base;\n    const prefix = it.tokens.prefix ? [\n      it.tokens.prefix.value,\n      ts.trivia(it.tokens.base.trivia)\n    ] : [];\n    const ref = reference(ts.wrap([\n      ...prefix,\n      it.tokens.base.value,\n      token(it.tokens.postfix)\n    ]), { unescaped: it.idlType, context: it });\n    return ts.wrap([ts.trivia(firstToken.trivia), ref]);\n  }\n  function type(it) {\n    return ts.wrap([\n      extended_attributes(it.extAttrs),\n      type_body(it),\n      token(it.tokens.nullable),\n      token(it.tokens.separator)\n    ]);\n  }\n  function default_(def) {\n    if (!def) {\n      return \"\";\n    }\n    return ts.wrap([\n      token(def.tokens.assign),\n      ...def.expression.map(t => token(t))\n    ]);\n  }\n  function argument(arg) {\n    return ts.wrap([\n      extended_attributes(arg.extAttrs),\n      token(arg.tokens.optional),\n      ts.type(type(arg.idlType)),\n      token(arg.tokens.variadic),\n      name_token(arg.tokens.name, { data: arg }),\n      default_(arg.default),\n      token(arg.tokens.separator)\n    ]);\n  }\n  function identifier(id, context) {\n    return ts.wrap([\n      reference_token(id.tokens.value, context),\n      token(id.tokens.separator)\n    ]);\n  }\n  function make_ext_at(it) {\n    const { rhsType } = it.params;\n    return ts.wrap([\n      ts.trivia(it.tokens.name.trivia),\n      ts.extendedAttribute(ts.wrap([\n        ts.extendedAttributeReference(it.name),\n        token(it.params.tokens.assign),\n        reference_token(it.params.tokens.secondaryName, it),\n        token(it.params.tokens.open),\n        ...!it.params.list ? [] :\n          it.params.list.map(\n            rhsType === \"identifier-list\" ? id => identifier(id, it) : argument\n          ),\n        token(it.params.tokens.close)\n      ])),\n      token(it.tokens.separator)\n    ]);\n  }\n  function extended_attributes(eats) {\n    if (!eats.length) return \"\";\n    return ts.wrap([\n      token(eats.tokens.open),\n      ...eats.map(make_ext_at),\n      token(eats.tokens.close)\n    ]);\n  }\n\n  function operation(it, parent) {\n    const body = it.idlType ? [\n      ts.type(type(it.idlType)),\n      name_token(it.tokens.name, { data: it, parent }),\n      token(it.tokens.open),\n      ts.wrap(it.arguments.map(argument)),\n      token(it.tokens.close),\n    ] : [];\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.special),\n      ...body,\n      token(it.tokens.termination)\n    ]), { data: it, parent });\n  }\n\n  function attribute(it, parent) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.special),\n      token(it.tokens.readonly),\n      token(it.tokens.base),\n      ts.type(type(it.idlType)),\n      name_token(it.tokens.name, { data: it, parent }),\n      token(it.tokens.termination)\n    ]), { data: it, parent });\n  }\n\n  function inheritance(inh) {\n    if (!inh.tokens.inheritance) {\n      return \"\";\n    }\n    return ts.wrap([\n      token(inh.tokens.colon),\n      ts.trivia(inh.tokens.inheritance.trivia),\n      ts.inheritance(reference(inh.tokens.inheritance.value, { context: inh }))\n    ]);\n  }\n\n  function container(it) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.callback),\n      token(it.tokens.partial),\n      token(it.tokens.base),\n      token(it.tokens.mixin),\n      name_token(it.tokens.name, { data: it }),\n      inheritance(it),\n      token(it.tokens.open),\n      iterate(it.members, it),\n      token(it.tokens.close),\n      token(it.tokens.termination)\n    ]), { data: it });\n  }\n\n  function field(it, parent) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.required),\n      ts.type(type(it.idlType)),\n      name_token(it.tokens.name, { data: it, parent }),\n      default_(it.default),\n      token(it.tokens.termination)\n    ]), { data: it, parent });\n  }\n  function const_(it, parent) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.base),\n      ts.type(type(it.idlType)),\n      name_token(it.tokens.name, { data: it, parent }),\n      token(it.tokens.assign),\n      token(it.tokens.value),\n      token(it.tokens.termination)\n    ]), { data: it, parent });\n  }\n  function typedef(it) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.base),\n      ts.type(type(it.idlType)),\n      name_token(it.tokens.name, { data: it }),\n      token(it.tokens.termination)\n    ]), { data: it });\n  }\n  function includes(it) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      reference_token(it.tokens.target, it),\n      token(it.tokens.includes),\n      reference_token(it.tokens.mixin, it),\n      token(it.tokens.termination)\n    ]), { data: it });\n  }\n  function callback(it) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.base),\n      name_token(it.tokens.name, { data: it }),\n      token(it.tokens.assign),\n      ts.type(type(it.idlType)),\n      token(it.tokens.open),\n      ...it.arguments.map(argument),\n      token(it.tokens.close),\n      token(it.tokens.termination),\n    ]), { data: it });\n  }\n  function enum_(it) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.base),\n      name_token(it.tokens.name, { data: it }),\n      token(it.tokens.open),\n      iterate(it.values, it),\n      token(it.tokens.close),\n      token(it.tokens.termination)\n    ]), { data: it });\n  }\n  function enum_value(v, parent) {\n    return ts.wrap([\n      ts.trivia(v.tokens.value.trivia),\n      ts.definition(\n        ts.wrap(['\"', ts.name(v.value, { data: v, parent }), '\"']),\n        { data: v, parent }\n      ),\n      token(v.tokens.separator)\n    ]);\n  }\n  function iterable_like(it, parent) {\n    return ts.definition(ts.wrap([\n      extended_attributes(it.extAttrs),\n      token(it.tokens.readonly),\n      token(it.tokens.async),\n      token(it.tokens.base, ts.generic),\n      token(it.tokens.open),\n      ts.wrap(it.idlType.map(type)),\n      token(it.tokens.close),\n      token(it.tokens.termination)\n    ]), { data: it, parent });\n  }\n  function eof(it) {\n    return ts.trivia(it.trivia);\n  }\n\n  const table = {\n    interface: container,\n    \"interface mixin\": container,\n    namespace: container,\n    operation,\n    attribute,\n    dictionary: container,\n    field,\n    const: const_,\n    typedef,\n    includes,\n    callback,\n    enum: enum_,\n    \"enum-value\": enum_value,\n    iterable: iterable_like,\n    legacyiterable: iterable_like,\n    maplike: iterable_like,\n    setlike: iterable_like,\n    \"callback interface\": container,\n    eof\n  };\n  function dispatch(it, parent) {\n    const dispatcher = table[it.type];\n    if (!dispatcher) {\n      throw new Error(`Type \"${it.type}\" is unsupported`);\n    }\n    return table[it.type](it, parent);\n  }\n  function iterate(things, parent) {\n    if (!things) return;\n    const results = things.map(thing => dispatch(thing, parent));\n    return ts.wrap(results);\n  }\n  return iterate(ast);\n}\n","\"use strict\";\n\nimport { validationError as error } from \"./error.js\";\n\nfunction getMixinMap(all, unique) {\n  const map = new Map();\n  const includes = all.filter(def => def.type === \"includes\");\n  for (const include of includes) {\n    const mixin = unique.get(include.includes);\n    if (!mixin) {\n      continue;\n    }\n    const array = map.get(include.target);\n    if (array) {\n      array.push(mixin);\n    } else {\n      map.set(include.target, [mixin]);\n    }\n  }\n  return map;\n}\n\nfunction groupDefinitions(all) {\n  const unique = new Map();\n  const duplicates = new Set();\n  const partials = new Map();\n  for (const def of all) {\n    if (def.partial) {\n      const array = partials.get(def.name);\n      if (array) {\n        array.push(def);\n      } else {\n        partials.set(def.name, [def]);\n      }\n      continue;\n    }\n    if (!def.name) {\n      continue;\n    }\n    if (!unique.has(def.name)) {\n      unique.set(def.name, def);\n    } else {\n      duplicates.add(def);\n    }\n  }\n  return {\n    all,\n    unique,\n    partials,\n    duplicates,\n    mixinMap: getMixinMap(all, unique),\n    cache: {\n      typedefIncludesDictionary: new WeakMap()\n    },\n  };\n}\n\nfunction* checkDuplicatedNames({ unique, duplicates }) {\n  for (const dup of duplicates) {\n    const { name } = dup;\n    const message = `The name \"${name}\" of type \"${unique.get(name).type}\" was already seen`;\n    yield error(dup.source, dup.tokens.name, dup, message);\n  }\n}\n\nfunction* validateIterable(ast) {\n  const defs = groupDefinitions(ast);\n  for (const def of defs.all) {\n    if (def.validate) {\n      yield* def.validate(defs);\n    }\n  }\n  yield* checkDuplicatedNames(defs);\n}\n\n// Remove this once all of our support targets expose `.flat()` by default\nfunction flatten(array) {\n  if (array.flat) {\n    return array.flat();\n  }\n  return [].concat(...array);\n}\n\n/**\n * @param {*} ast AST or array of ASTs\n */\nexport function validate(ast) {\n  return [...validateIterable(flatten(ast))];\n}\n","export { parse } from \"./lib/webidl2.js\";\nexport { write } from \"./lib/writer.js\";\nexport { validate } from \"./lib/validator.js\";\n"],"sourceRoot":""}